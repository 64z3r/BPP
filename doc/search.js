window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "bpp", "modulename": "bpp", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data", "modulename": "bpp.data", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNet", "modulename": "bpp.data", "qualname": "PUResNet", "kind": "class", "doc": "<p>Dataset module for the PUResNet dataset.</p>\n\n<p>This module will download all necessary datasets and process them according\nto a provided configuration. You can also select which datasets should be\nused for training, validation or testing. The resulting samples are PyTorch\nGeometric data instances.</p>\n\n<h6 id=\"references\">References:</h6>\n\n<blockquote>\n  <p>[^1]: Kandel, J., Tayara, H. &amp; Chong, K.T. PUResNet: prediction of\n        protein-ligand binding sites using deep residual neural network. J\n        Cheminform 13, 65 (2021). <a href=\"https://doi.org/10.1186/s13321-021-00547-7V\">https://doi.org/10.1186/s13321-021-00547-7V</a></p>\n</blockquote>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "bpp.data.PUResNet.__init__", "modulename": "bpp.data", "qualname": "PUResNet.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>sets:</strong>  Datasets that should be included. Possible choices are:\n<ul>\n<li><code>\"scpdb\"</code>: Subset of the scPDB dataset. <em>Hint</em>: use as\ntraining set.</li>\n<li><code>\"coach\"</code>: Coach dataset with proteins removed that are\npresent in the scPDB dataset. <em>Hint</em>: use as validation set.</li>\n<li><code>\"bu48\"</code>: BU48 dataset with proteins removed that are present\nin the scPDB and Coach datasets. <em>Hint</em>: add to validation\nset or use as test set.</li>\n</ul></li>\n<li><strong>root:</strong>  Directory where to store the raw and processed datasets and\nsamples.</li>\n<li><strong>conf:</strong>  Configuration that determines how the protein-ligand samples\nshould be processed.</li>\n<li><strong>transform:</strong>  Callable that takes a data instance and returns a\ntransformed version.</li>\n<li><strong>n_jobs:</strong>  Number of parallel jobs for processing the samples. If\nsmaller or equal to zero, the maximum number of supported\nparallel threads will be used.</li>\n<li><strong>verbose:</strong>  Verbosity level. Choices are:\n<ul>\n<li><code>1</code>: Nothing will be printed, except for some most critical\nerrors.</li>\n<li><code>2</code>: Only a progress bar will be shown.</li>\n<li><code>3</code>: All warnings etc. will be printed, without a progress\nbar.</li>\n</ul></li>\n<li><strong>cleanup_on_error:</strong>  Whether the directory with processed samples\nshould be deleted if an error occurs.</li>\n<li><strong>constructor_cls:</strong>  Class instance of the constructor for processing\nprotein-ligand samples.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">sets</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;scpdb&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;coach&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;bu48&#39;</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">&#39;scpdb&#39;</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">root</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;./dataset/&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">conf</span><span class=\"p\">:</span> <span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Configuration</span> <span class=\"o\">=</span> <span class=\"n\">Configuration</span><span class=\"p\">(</span><span class=\"n\">granularity</span><span class=\"o\">=</span><span class=\"s1\">&#39;atom&#39;</span><span class=\"p\">,</span> <span class=\"n\">insertions</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">deprotonate</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">exclude_waters</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">alternate_locations</span><span class=\"o\">=</span><span class=\"s1\">&#39;max_occupancy&#39;</span><span class=\"p\">,</span> <span class=\"n\">binding_site_cutoff</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">surface_cutoff</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">elements</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;N&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;O&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;H&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;S&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;C&#39;</span><span class=\"p\">},</span> <span class=\"n\">residues</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;LYS&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GLY&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ALA&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;LEU&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;VAL&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;THR&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ASP&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;PRO&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;MET&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CYS&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;HIS&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ARG&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GLN&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;SER&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;PHE&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;GLU&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;TYR&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;TRP&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ASN&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ILE&#39;</span><span class=\"p\">},</span> <span class=\"n\">construction</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"o\">&lt;</span><span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">construction</span><span class=\"o\">.</span><span class=\"n\">edge</span><span class=\"o\">.</span><span class=\"n\">Covalent</span> <span class=\"nb\">object</span><span class=\"o\">&gt;</span><span class=\"p\">],</span> <span class=\"n\">annotation</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"o\">&lt;</span><span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">annotation</span><span class=\"o\">.</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">LigandDistances</span> <span class=\"nb\">object</span><span class=\"o\">&gt;</span><span class=\"p\">,</span> <span class=\"o\">&lt;</span><span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">annotation</span><span class=\"o\">.</span><span class=\"n\">node</span><span class=\"o\">.</span><span class=\"n\">SurfaceDistance</span> <span class=\"nb\">object</span><span class=\"o\">&gt;</span><span class=\"p\">])</span>,</span><span class=\"param\">\t<span class=\"n\">transform</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span><span class=\"p\">],</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">n_jobs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">cleanup_on_error</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\tconstructor_cls: type[bpp.data.graph.Constructor] = &lt;class &#x27;bpp.data.graph.Constructor&#x27;&gt;</span>)</span>"}, {"fullname": "bpp.data.PUResNet.DATASET_URLS", "modulename": "bpp.data", "qualname": "PUResNet.DATASET_URLS", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;scpdb&#x27;: &#x27;https://github.com/jivankandel/PUResNet/raw/main/scpdb_subset.zip?download=&#x27;, &#x27;coach&#x27;: &#x27;https://github.com/jivankandel/PUResNet/raw/main/coach.zip?download=&#x27;, &#x27;bu48&#x27;: &#x27;https://github.com/jivankandel/PUResNet/raw/main/BU48.zip?download=&#x27;}"}, {"fullname": "bpp.data.PUResNet.DATASET_FILES", "modulename": "bpp.data", "qualname": "PUResNet.DATASET_FILES", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;scpdb&#x27;: &#x27;scpdb_subset.zip&#x27;, &#x27;coach&#x27;: &#x27;coach.zip&#x27;, &#x27;bu48&#x27;: &#x27;BU48.zip&#x27;}"}, {"fullname": "bpp.data.PUResNet.sets", "modulename": "bpp.data", "qualname": "PUResNet.sets", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNet.conf", "modulename": "bpp.data", "qualname": "PUResNet.conf", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNet.n_jobs", "modulename": "bpp.data", "qualname": "PUResNet.n_jobs", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNet.verbose", "modulename": "bpp.data", "qualname": "PUResNet.verbose", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNet.cleanup_on_error", "modulename": "bpp.data", "qualname": "PUResNet.cleanup_on_error", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNet.constructor_cls", "modulename": "bpp.data", "qualname": "PUResNet.constructor_cls", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNet.raw_file_names", "modulename": "bpp.data", "qualname": "PUResNet.raw_file_names", "kind": "variable", "doc": "<p>File names of the raw datasets.</p>\n", "annotation": ": list[str]"}, {"fullname": "bpp.data.PUResNet.processed_file_names", "modulename": "bpp.data", "qualname": "PUResNet.processed_file_names", "kind": "variable", "doc": "<p>File names of processed samples. Actually, just the directories\nthat contain the samples of a respective dataset.</p>\n", "annotation": ": list[str]"}, {"fullname": "bpp.data.PUResNet.download", "modulename": "bpp.data", "qualname": "PUResNet.download", "kind": "function", "doc": "<p>Download raw datasets.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNet.process_sample", "modulename": "bpp.data", "qualname": "PUResNet.process_sample", "kind": "function", "doc": "<p>Process single protein-ligand sample.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>zf_path:</strong>  Path to zip-file containing all protein-ligand files.</li>\n<li><strong>pr_subpath:</strong>  Subpath of protein within zip-file that should be\nprocessed.</li>\n<li><strong>processed_dir:</strong>  Directory where to store processed samples.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">zf_path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span>,</span><span class=\"param\">\t<span class=\"n\">pr_subpath</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span>,</span><span class=\"param\">\t<span class=\"n\">processed_dir</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNet.process", "modulename": "bpp.data", "qualname": "PUResNet.process", "kind": "function", "doc": "<p>Process raw samples.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNet.len", "modulename": "bpp.data", "qualname": "PUResNet.len", "kind": "function", "doc": "<p>Number of samples in dataset.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNet.get", "modulename": "bpp.data", "qualname": "PUResNet.get", "kind": "function", "doc": "<p>Get sample from dataset.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>idx:</strong>  Index of sample.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Sample with index <code>idx</code>.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">idx</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNet.info", "modulename": "bpp.data", "qualname": "PUResNet.info", "kind": "function", "doc": "<p>Get additional sample information.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>idx:</strong>  Index of sample.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Additional sample information.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">idx</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNetDataModule", "modulename": "bpp.data", "qualname": "PUResNetDataModule", "kind": "class", "doc": "<p>Lightning datamodule for the PUResNet dataset.</p>\n", "bases": "pytorch_lightning.core.datamodule.LightningDataModule"}, {"fullname": "bpp.data.PUResNetDataModule.__init__", "modulename": "bpp.data", "qualname": "PUResNetDataModule.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>train_sets:</strong>  List of datasets for training.</li>\n<li><strong>val_sets:</strong>  List of datasets for validation.</li>\n<li><strong>test_sets:</strong>  List of datasets for testing.</li>\n<li><strong>dataset_setup:</strong>  Callable that takes a list of requested datasets\nand returns a dataset instance with the respective datasets.</li>\n<li><strong>batch_size:</strong>  Batch size for dataloaders.</li>\n<li><strong>shuffle:</strong>  Whether batches in training dataloader should be shuffled.</li>\n<li><strong>num_workers:</strong>  Number of workers.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">train_sets</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">val_sets</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">test_sets</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dataset_setup</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]],</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">shuffle</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span>)</span>"}, {"fullname": "bpp.data.PUResNetDataModule.train_sets", "modulename": "bpp.data", "qualname": "PUResNetDataModule.train_sets", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.val_sets", "modulename": "bpp.data", "qualname": "PUResNetDataModule.val_sets", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.test_sets", "modulename": "bpp.data", "qualname": "PUResNetDataModule.test_sets", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.dataset_setup", "modulename": "bpp.data", "qualname": "PUResNetDataModule.dataset_setup", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.batch_size", "modulename": "bpp.data", "qualname": "PUResNetDataModule.batch_size", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.shuffle", "modulename": "bpp.data", "qualname": "PUResNetDataModule.shuffle", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.num_workers", "modulename": "bpp.data", "qualname": "PUResNetDataModule.num_workers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.train_dataset", "modulename": "bpp.data", "qualname": "PUResNetDataModule.train_dataset", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.val_dataset", "modulename": "bpp.data", "qualname": "PUResNetDataModule.val_dataset", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.test_dataset", "modulename": "bpp.data", "qualname": "PUResNetDataModule.test_dataset", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.PUResNetDataModule.prepare_data", "modulename": "bpp.data", "qualname": "PUResNetDataModule.prepare_data", "kind": "function", "doc": "<p>Download and process datasets.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNetDataModule.setup", "modulename": "bpp.data", "qualname": "PUResNetDataModule.setup", "kind": "function", "doc": "<p>Setup datasets for training and testing.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>stage:</strong>  At which stage this method is called. With <code>\"fit\"</code> instances\nfor the training and validation datasets will be created, with\n<code>\"test\"</code> an instance for the testing dataset.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">stage</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNetDataModule.train_dataloader", "modulename": "bpp.data", "qualname": "PUResNetDataModule.train_dataloader", "kind": "function", "doc": "<p>Returns the training dataloader.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Training dataloader.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNetDataModule.val_dataloader", "modulename": "bpp.data", "qualname": "PUResNetDataModule.val_dataloader", "kind": "function", "doc": "<p>Returns the validation dataloader.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Validation dataloader.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.PUResNetDataModule.test_dataloader", "modulename": "bpp.data", "qualname": "PUResNetDataModule.test_dataloader", "kind": "function", "doc": "<p>Returns the testing dataloader.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Testing dataloader.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">loader</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.constants", "modulename": "bpp.data.constants", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.constants.ALLOWABLE_ELEMENTS", "modulename": "bpp.data.constants", "qualname": "ALLOWABLE_ELEMENTS", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]", "default_value": "[&#x27;C&#x27;, &#x27;O&#x27;, &#x27;N&#x27;, &#x27;H&#x27;, &#x27;S&#x27;]"}, {"fullname": "bpp.data.constants.ALLOWABLE_RESIDUES", "modulename": "bpp.data.constants", "qualname": "ALLOWABLE_RESIDUES", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]", "default_value": "[&#x27;GLU&#x27;, &#x27;GLY&#x27;, &#x27;LEU&#x27;, &#x27;MET&#x27;, &#x27;GLN&#x27;, &#x27;LYS&#x27;, &#x27;ARG&#x27;, &#x27;ILE&#x27;, &#x27;VAL&#x27;, &#x27;ALA&#x27;, &#x27;ASN&#x27;, &#x27;HIS&#x27;, &#x27;SER&#x27;, &#x27;TRP&#x27;, &#x27;PHE&#x27;, &#x27;THR&#x27;, &#x27;TYR&#x27;, &#x27;ASP&#x27;, &#x27;PRO&#x27;, &#x27;CYS&#x27;]"}, {"fullname": "bpp.data.graph", "modulename": "bpp.data.graph", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.logger", "modulename": "bpp.data.graph", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger bpp.data.graph (WARNING)&gt;"}, {"fullname": "bpp.data.graph.ELEMENT_LABEL_ENCODER", "modulename": "bpp.data.graph", "qualname": "ELEMENT_LABEL_ENCODER", "kind": "variable", "doc": "<p></p>\n", "default_value": "LabelEncoder()"}, {"fullname": "bpp.data.graph.RESIDUE_LABEL_ENCODER", "modulename": "bpp.data.graph", "qualname": "RESIDUE_LABEL_ENCODER", "kind": "variable", "doc": "<p></p>\n", "default_value": "LabelEncoder()"}, {"fullname": "bpp.data.graph.Configuration", "modulename": "bpp.data.graph", "qualname": "Configuration", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Configuration.__init__", "modulename": "bpp.data.graph", "qualname": "Configuration.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">granularity</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;N&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CA&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;C&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;O&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CB&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;OG&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CG&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CD1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CD2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CE1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CE2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CZ&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;OD1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ND2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CG1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CG2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CD&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CE&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;NZ&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;OD2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;OE1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;NE2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;OE2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;OH&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;NE&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;NH1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;NH2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;OG1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;SD&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ND1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;SG&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;NE1&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CE3&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CZ2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CZ3&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;CH2&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;OXT&#39;</span><span class=\"p\">],</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;atom&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;centroids&#39;</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;atom&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">insertions</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">deprotonate</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">exclude_waters</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">alternate_locations</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;max_occupancy&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;min_occupancy&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;first&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;last&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;exclude&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;include&#39;</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;max_occupancy&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">binding_site_cutoff</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>,</span><span class=\"param\">\t<span class=\"n\">surface_cutoff</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">elements</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">factory</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">residues</span><span class=\"p\">:</span> <span class=\"nb\">set</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">factory</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">construction</span><span class=\"p\">:</span> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">operator</span><span class=\"o\">.</span><span class=\"n\">Operator</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">factory</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">annotation</span><span class=\"p\">:</span> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">operator</span><span class=\"o\">.</span><span class=\"n\">Operator</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">factory</span><span class=\"o\">&gt;</span></span>)</span>"}, {"fullname": "bpp.data.graph.Configuration.granularity", "modulename": "bpp.data.graph", "qualname": "Configuration.granularity", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[Literal[&#x27;N&#x27;, &#x27;CA&#x27;, &#x27;C&#x27;, &#x27;O&#x27;, &#x27;CB&#x27;, &#x27;OG&#x27;, &#x27;CG&#x27;, &#x27;CD1&#x27;, &#x27;CD2&#x27;, &#x27;CE1&#x27;, &#x27;CE2&#x27;, &#x27;CZ&#x27;, &#x27;OD1&#x27;, &#x27;ND2&#x27;, &#x27;CG1&#x27;, &#x27;CG2&#x27;, &#x27;CD&#x27;, &#x27;CE&#x27;, &#x27;NZ&#x27;, &#x27;OD2&#x27;, &#x27;OE1&#x27;, &#x27;NE2&#x27;, &#x27;OE2&#x27;, &#x27;OH&#x27;, &#x27;NE&#x27;, &#x27;NH1&#x27;, &#x27;NH2&#x27;, &#x27;OG1&#x27;, &#x27;SD&#x27;, &#x27;ND1&#x27;, &#x27;SG&#x27;, &#x27;NE1&#x27;, &#x27;CE3&#x27;, &#x27;CZ2&#x27;, &#x27;CZ3&#x27;, &#x27;CH2&#x27;, &#x27;OXT&#x27;], Literal[&#x27;atom&#x27;, &#x27;centroids&#x27;]]", "default_value": "&#x27;atom&#x27;"}, {"fullname": "bpp.data.graph.Configuration.insertions", "modulename": "bpp.data.graph", "qualname": "Configuration.insertions", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "bpp.data.graph.Configuration.deprotonate", "modulename": "bpp.data.graph", "qualname": "Configuration.deprotonate", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "bpp.data.graph.Configuration.exclude_waters", "modulename": "bpp.data.graph", "qualname": "Configuration.exclude_waters", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "bpp.data.graph.Configuration.alternate_locations", "modulename": "bpp.data.graph", "qualname": "Configuration.alternate_locations", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[bool, Literal[&#x27;max_occupancy&#x27;, &#x27;min_occupancy&#x27;, &#x27;first&#x27;, &#x27;last&#x27;, &#x27;exclude&#x27;, &#x27;include&#x27;]]", "default_value": "&#x27;max_occupancy&#x27;"}, {"fullname": "bpp.data.graph.Configuration.binding_site_cutoff", "modulename": "bpp.data.graph", "qualname": "Configuration.binding_site_cutoff", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "4"}, {"fullname": "bpp.data.graph.Configuration.surface_cutoff", "modulename": "bpp.data.graph", "qualname": "Configuration.surface_cutoff", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float | None", "default_value": "None"}, {"fullname": "bpp.data.graph.Configuration.elements", "modulename": "bpp.data.graph", "qualname": "Configuration.elements", "kind": "variable", "doc": "<p></p>\n", "annotation": ": set[str]"}, {"fullname": "bpp.data.graph.Configuration.residues", "modulename": "bpp.data.graph", "qualname": "Configuration.residues", "kind": "variable", "doc": "<p></p>\n", "annotation": ": set[str]"}, {"fullname": "bpp.data.graph.Configuration.construction", "modulename": "bpp.data.graph", "qualname": "Configuration.construction", "kind": "variable", "doc": "<p></p>\n", "annotation": ": dict[str, bpp.data.graph.operator.Operator]"}, {"fullname": "bpp.data.graph.Configuration.annotation", "modulename": "bpp.data.graph", "qualname": "Configuration.annotation", "kind": "variable", "doc": "<p></p>\n", "annotation": ": dict[str, bpp.data.graph.operator.Operator]"}, {"fullname": "bpp.data.graph.Configuration.state", "modulename": "bpp.data.graph", "qualname": "Configuration.state", "kind": "variable", "doc": "<p>Return hashable state of configuration.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Hashable state.</p>\n</blockquote>\n", "annotation": ": dict[str, typing.Any]"}, {"fullname": "bpp.data.graph.Featurizer", "modulename": "bpp.data.graph", "qualname": "Featurizer", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Featurizer.__init__", "modulename": "bpp.data.graph", "qualname": "Featurizer.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">constructor</span><span class=\"p\">:</span> <span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Constructor</span>,</span><span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">kind</span><span class=\"p\">:</span> <span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">operator</span><span class=\"o\">.</span><span class=\"n\">AnnotationKind</span>,</span><span class=\"param\">\t<span class=\"n\">getter</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]</span></span>)</span>"}, {"fullname": "bpp.data.graph.Featurizer.constructor", "modulename": "bpp.data.graph", "qualname": "Featurizer.constructor", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Featurizer.name", "modulename": "bpp.data.graph", "qualname": "Featurizer.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Featurizer.kind", "modulename": "bpp.data.graph", "qualname": "Featurizer.kind", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Featurizer.getter", "modulename": "bpp.data.graph", "qualname": "Featurizer.getter", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Featurizer.get", "modulename": "bpp.data.graph", "qualname": "Featurizer.get", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.Featurizer.features", "modulename": "bpp.data.graph", "qualname": "Featurizer.features", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]"}, {"fullname": "bpp.data.graph.NodeFeaturizer", "modulename": "bpp.data.graph", "qualname": "NodeFeaturizer", "kind": "class", "doc": "<p></p>\n", "bases": "Featurizer"}, {"fullname": "bpp.data.graph.NodeFeaturizer.__init__", "modulename": "bpp.data.graph", "qualname": "NodeFeaturizer.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">constructor</span><span class=\"p\">:</span> <span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Constructor</span>, </span><span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "bpp.data.graph.NodeFeaturizer.coords", "modulename": "bpp.data.graph", "qualname": "NodeFeaturizer.coords", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]"}, {"fullname": "bpp.data.graph.NodeFeaturizer.surface_distance", "modulename": "bpp.data.graph", "qualname": "NodeFeaturizer.surface_distance", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]"}, {"fullname": "bpp.data.graph.NodeFeaturizer.surface", "modulename": "bpp.data.graph", "qualname": "NodeFeaturizer.surface", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray[typing.Any, numpy.dtype[numpy.bool_]]"}, {"fullname": "bpp.data.graph.NodeFeaturizer.binding_sites", "modulename": "bpp.data.graph", "qualname": "NodeFeaturizer.binding_sites", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray[typing.Any, numpy.dtype[numpy.bool_]]"}, {"fullname": "bpp.data.graph.NodeFeaturizer.binding_site_centers", "modulename": "bpp.data.graph", "qualname": "NodeFeaturizer.binding_site_centers", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]"}, {"fullname": "bpp.data.graph.EdgeFeaturizer", "modulename": "bpp.data.graph", "qualname": "EdgeFeaturizer", "kind": "class", "doc": "<p></p>\n", "bases": "Featurizer"}, {"fullname": "bpp.data.graph.EdgeFeaturizer.__init__", "modulename": "bpp.data.graph", "qualname": "EdgeFeaturizer.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">constructor</span><span class=\"p\">:</span> <span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Constructor</span>, </span><span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "bpp.data.graph.EdgeFeaturizer.index", "modulename": "bpp.data.graph", "qualname": "EdgeFeaturizer.index", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[tuple[int, int]]"}, {"fullname": "bpp.data.graph.EdgeFeaturizer.kinds", "modulename": "bpp.data.graph", "qualname": "EdgeFeaturizer.kinds", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]"}, {"fullname": "bpp.data.graph.EdgeFeaturizer.labels", "modulename": "bpp.data.graph", "qualname": "EdgeFeaturizer.labels", "kind": "variable", "doc": "<p></p>\n", "annotation": ": numpy.ndarray[typing.Any, numpy.dtype[numpy.bool_]]"}, {"fullname": "bpp.data.graph.Constructor", "modulename": "bpp.data.graph", "qualname": "Constructor", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Constructor.__init__", "modulename": "bpp.data.graph", "qualname": "Constructor.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">conf</span><span class=\"p\">:</span> <span class=\"n\">bpp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Configuration</span></span>)</span>"}, {"fullname": "bpp.data.graph.Constructor.path", "modulename": "bpp.data.graph", "qualname": "Constructor.path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Constructor.conf", "modulename": "bpp.data.graph", "qualname": "Constructor.conf", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.Constructor.name", "modulename": "bpp.data.graph", "qualname": "Constructor.name", "kind": "variable", "doc": "<p>Name of the sample that is processed.</p>\n", "annotation": ": str"}, {"fullname": "bpp.data.graph.Constructor.node", "modulename": "bpp.data.graph", "qualname": "Constructor.node", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.NodeFeaturizer"}, {"fullname": "bpp.data.graph.Constructor.edge", "modulename": "bpp.data.graph", "qualname": "Constructor.edge", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.EdgeFeaturizer"}, {"fullname": "bpp.data.graph.Constructor.nxg", "modulename": "bpp.data.graph", "qualname": "Constructor.nxg", "kind": "variable", "doc": "<p>NetworkX graph.</p>\n\n<p>Intermediate structure from which the final graph is build.</p>\n", "annotation": ": networkx.classes.graph.Graph"}, {"fullname": "bpp.data.graph.Constructor.get", "modulename": "bpp.data.graph", "qualname": "Constructor.get", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Any</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.Constructor.construct", "modulename": "bpp.data.graph", "qualname": "Constructor.construct", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.annotation", "modulename": "bpp.data.graph.annotation", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.edge", "modulename": "bpp.data.graph.annotation.edge", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.edge.EdgeAngle", "modulename": "bpp.data.graph.annotation.edge", "qualname": "EdgeAngle", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.GraphOperator"}, {"fullname": "bpp.data.graph.annotation.edge.EdgeAngle.__init__", "modulename": "bpp.data.graph.annotation.edge", "qualname": "EdgeAngle.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">name_vec_i</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">name_vec_j</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "bpp.data.graph.annotation.edge.EdgeAngle.kind", "modulename": "bpp.data.graph.annotation.edge", "qualname": "EdgeAngle.kind", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.AnnotationKind", "default_value": "&lt;AnnotationKind.EDGE: 4&gt;"}, {"fullname": "bpp.data.graph.annotation.edge.EdgeAngle.name_vec_i", "modulename": "bpp.data.graph.annotation.edge", "qualname": "EdgeAngle.name_vec_i", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.edge.EdgeAngle.name_vec_j", "modulename": "bpp.data.graph.annotation.edge", "qualname": "EdgeAngle.name_vec_j", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.graph", "modulename": "bpp.data.graph.annotation.graph", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.node", "modulename": "bpp.data.graph.annotation.node", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.node.logger", "modulename": "bpp.data.graph.annotation.node", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;Level bpp.data.graph.annotation.node&#x27;"}, {"fullname": "bpp.data.graph.annotation.node.Expasy", "modulename": "bpp.data.graph.annotation.node", "qualname": "Expasy", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.NodeAnnotationFunctionOperator"}, {"fullname": "bpp.data.graph.annotation.node.Expasy.function", "modulename": "bpp.data.graph.annotation.node", "qualname": "Expasy.function", "kind": "function", "doc": "<p>Return amino acid features that come from the EXPASY protein scale.</p>\n\n<p>Source: <a href=\"https://web.expasy.org/protscale/\">https://web.expasy.org/protscale/</a></p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>n</strong>:  Node in a NetworkX graph</li>\n<li><strong>d</strong>:  NetworkX node attributes.</li>\n<li><strong>selection</strong>:  List of columns to select. Viewable in\n:ref:<code>~graphein.protein.features.nodes.meiler_embeddings</code>.</li>\n<li><strong>add_separate</strong>:  Whether or not to add the expasy features as individual\nentries or as a series.</li>\n<li><strong>return_array</strong>:  Bool indicating whether or not to return a\n<code>np.ndarray</code> of the features. Default is <code>pd.Series</code>.\n:returns: pd.Series of amino acid features</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">d</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">selection</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">add_separate</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">return_array</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">series</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.annotation.node.Expasy.id", "modulename": "bpp.data.graph.annotation.node", "qualname": "Expasy.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;expasy&#x27;"}, {"fullname": "bpp.data.graph.annotation.node.Expasy.selection", "modulename": "bpp.data.graph.annotation.node", "qualname": "Expasy.selection", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str] | None", "default_value": "None"}, {"fullname": "bpp.data.graph.annotation.node.Expasy.default_args", "modulename": "bpp.data.graph.annotation.node", "qualname": "Expasy.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;selection&#x27;: None}"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondAcceptors", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondAcceptors", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.NodeAnnotationFunctionOperator"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondAcceptors.function", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondAcceptors.function", "kind": "function", "doc": "<p>Adds Hydrogen Bond Acceptor status to nodes as a feature.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>n</strong>:  Node id</li>\n<li><strong>d</strong>:  Dict of node attributes.</li>\n<li><strong>sum_features</strong>:  If <code>True</code>, the feature is the number of hydrogen\nbond acceptors per node. If <code>False</code>, the feature is a boolean\nindicating whether or not the node has a hydrogen bond acceptor.\nDefault is <code>True</code>.</li>\n<li><strong>return_array</strong>:  If <code>True</code>, returns a <code>np.ndarray</code>, otherwise\nreturns a <code>pd.Series</code>. Default is <code>True</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n</span>,</span><span class=\"param\">\t<span class=\"n\">d</span>,</span><span class=\"param\">\t<span class=\"n\">sum_features</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">return_array</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">series</span><span class=\"o\">.</span><span class=\"n\">Series</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondAcceptors.id", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondAcceptors.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;hbond_acceptors&#x27;"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondAcceptors.sum_features", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondAcceptors.sum_features", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondAcceptors.default_args", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondAcceptors.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;sum_features&#x27;: True}"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondDonors", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondDonors", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.NodeAnnotationFunctionOperator"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondDonors.function", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondDonors.function", "kind": "function", "doc": "<p>Adds Hydrogen Bond Donor status to nodes as a feature.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>n</strong>:  Node id</li>\n<li><strong>d</strong>:  Dict of node attributes</li>\n<li><strong>sum_features</strong>:  If <code>True</code>, the feature is the number of hydrogen\nbond donors per node. If <code>False</code>, the feature is a boolean indicating\nwhether or not the node has a hydrogen bond donor. Default is <code>True</code>.</li>\n<li><strong>return_array</strong>:  If <code>True</code>, returns a <code>np.ndarray</code>, otherwise\nreturns a <code>pd.Series</code>. Default is <code>True</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">d</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">sum_features</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">return_array</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondDonors.id", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondDonors.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;hbond_donors&#x27;"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondDonors.sum_features", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondDonors.sum_features", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "bpp.data.graph.annotation.node.HydrogenBondDonors.default_args", "modulename": "bpp.data.graph.annotation.node", "qualname": "HydrogenBondDonors.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;sum_features&#x27;: True}"}, {"fullname": "bpp.data.graph.annotation.node.Meiler", "modulename": "bpp.data.graph.annotation.node", "qualname": "Meiler", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.NodeAnnotationFunctionOperator"}, {"fullname": "bpp.data.graph.annotation.node.Meiler.function", "modulename": "bpp.data.graph.annotation.node", "qualname": "Meiler.function", "kind": "function", "doc": "<p>Return amino acid features from reduced dimensional embeddings of amino\nacid physicochemical properties.</p>\n\n<p>Source: <a href=\"https://link.springer.com/article/10.1007/s008940100038\">https://link.springer.com/article/10.1007/s008940100038</a>\ndoi: <a href=\"https://doi.org/10.1007/s008940100038\">https://doi.org/10.1007/s008940100038</a></p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>n</strong>:  Node in a NetworkX graph</li>\n<li><strong>d</strong>:  NetworkX node attributes.</li>\n<li><strong>return_array</strong>:  Bool indicating whether or not to return a\n<code>np.ndarray</code> of the features. Default is <code>pd.Series</code>.\n:returns: pd.Series of amino acid features</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">n</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">d</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">return_array</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">series</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.annotation.node.Meiler.id", "modulename": "bpp.data.graph.annotation.node", "qualname": "Meiler.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;meiler&#x27;"}, {"fullname": "bpp.data.graph.annotation.node.Meiler.default_args", "modulename": "bpp.data.graph.annotation.node", "qualname": "Meiler.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.annotation.node.BetaCarbonVector", "modulename": "bpp.data.graph.annotation.node", "qualname": "BetaCarbonVector", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.GraphAnnotationFunctionOperator"}, {"fullname": "bpp.data.graph.annotation.node.BetaCarbonVector.function", "modulename": "bpp.data.graph.annotation.node", "qualname": "BetaCarbonVector.function", "kind": "function", "doc": "<p>Adds vector from node (typically alpha carbon) to position of beta\ncarbon.</p>\n\n<p>Glycine does not have a beta carbon, so we set it to\n<code>np.array([0., 0., 0.])</code>. We extract the position of the beta carbon from the\nunprocessed atomic PDB dataframe. For this we use the <code>raw_pdb_df</code>\nDataFrame. If <code>scale</code>, we scale the vector to the unit vector. If\n<code>reverse</code> is <code>True</code>, we reverse the vector (<code>C beta - node</code>).\nIf <code>reverse</code> is <code>False</code> (default) we compute (<code>node - C beta</code>).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>g</strong>:  Graph to add vector to.</li>\n<li><strong>scale</strong>:  Scale vector to unit vector. Defaults to <code>True</code>.</li>\n<li><strong>reverse</strong>:  Reverse vector. Defaults to <code>False</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">g</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">scale</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">reverse</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.annotation.node.BetaCarbonVector.id", "modulename": "bpp.data.graph.annotation.node", "qualname": "BetaCarbonVector.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;c_beta_vector&#x27;"}, {"fullname": "bpp.data.graph.annotation.node.BetaCarbonVector.kind", "modulename": "bpp.data.graph.annotation.node", "qualname": "BetaCarbonVector.kind", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.AnnotationKind", "default_value": "&lt;AnnotationKind.NODE: 2&gt;"}, {"fullname": "bpp.data.graph.annotation.node.BetaCarbonVector.scale", "modulename": "bpp.data.graph.annotation.node", "qualname": "BetaCarbonVector.scale", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "bpp.data.graph.annotation.node.BetaCarbonVector.reverse", "modulename": "bpp.data.graph.annotation.node", "qualname": "BetaCarbonVector.reverse", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "bpp.data.graph.annotation.node.BetaCarbonVector.default_args", "modulename": "bpp.data.graph.annotation.node", "qualname": "BetaCarbonVector.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;scale&#x27;: True, &#x27;reverse&#x27;: False}"}, {"fullname": "bpp.data.graph.annotation.node.SequenceNeighbourVector", "modulename": "bpp.data.graph.annotation.node", "qualname": "SequenceNeighbourVector", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.GraphAnnotationFunctionOperator"}, {"fullname": "bpp.data.graph.annotation.node.SequenceNeighbourVector.__init__", "modulename": "bpp.data.graph.annotation.node", "qualname": "SequenceNeighbourVector.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">n_to_c</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">scale</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">reverse</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "bpp.data.graph.annotation.node.SequenceNeighbourVector.function", "modulename": "bpp.data.graph.annotation.node", "qualname": "SequenceNeighbourVector.function", "kind": "function", "doc": "<p>Computes vector from node to adjacent node in sequence.\nTypically used with <code>CA</code> (alpha carbon) graphs.</p>\n\n<p>If <code>n_to_c</code> is <code>True</code> (default), we compute the vectors from the N\nterminus to the C terminus (canonical direction). If <code>reverse</code> is\n<code>False</code> (default), we compute <code>Node_i - Node_{i+1}</code>. If <code>reverse is\n</code>True<code>, we compute</code>Node_{i+1} - Node_i``.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>g</strong>:  Graph to add vector to.</li>\n<li><strong>scale</strong>:  Scale vector to unit vector. Defaults to <code>True</code>.</li>\n<li><strong>reverse</strong>:  Reverse vector. Defaults to <code>False</code>.</li>\n<li><strong>n_to_c</strong>:  Compute vector from N to C or C to N. Defaults to <code>True</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">g</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">scale</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">reverse</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">n_to_c</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.annotation.node.SequenceNeighbourVector.id", "modulename": "bpp.data.graph.annotation.node", "qualname": "SequenceNeighbourVector.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;sequence_neighbour_vector&#x27;"}, {"fullname": "bpp.data.graph.annotation.node.SequenceNeighbourVector.kind", "modulename": "bpp.data.graph.annotation.node", "qualname": "SequenceNeighbourVector.kind", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.AnnotationKind", "default_value": "&lt;AnnotationKind.NODE: 2&gt;"}, {"fullname": "bpp.data.graph.annotation.node.SequenceNeighbourVector.default_args", "modulename": "bpp.data.graph.annotation.node", "qualname": "SequenceNeighbourVector.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.annotation.node.SidechainVector", "modulename": "bpp.data.graph.annotation.node", "qualname": "SidechainVector", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.GraphAnnotationFunctionOperator"}, {"fullname": "bpp.data.graph.annotation.node.SidechainVector.function", "modulename": "bpp.data.graph.annotation.node", "qualname": "SidechainVector.function", "kind": "function", "doc": "<p>Adds vector from node to average position of sidechain atoms.</p>\n\n<p>We compute the mean of the sidechain atoms for each node. For this we use\nthe <code>rgroup_df</code> dataframe. If the graph does not contain the <code>rgroup_df</code>\ndataframe, we compute it from the <code>raw_pdb_df</code>. If <code>scale</code>, we scale\nthe vector to the unit vector. If <code>reverse</code> is <code>True</code>, we reverse the\nvector (<code>sidechain - node</code>). If reverse is false (default) we compute\n(<code>node - sidechain</code>).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>g</strong>:  Graph to add vector to.</li>\n<li><strong>scale</strong>:  Scale vector to unit vector. Defaults to <code>True</code>.</li>\n<li><strong>reverse</strong>:  Reverse vector. Defaults to <code>False</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">g</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">scale</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">reverse</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.annotation.node.SidechainVector.id", "modulename": "bpp.data.graph.annotation.node", "qualname": "SidechainVector.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;sidechain_vector&#x27;"}, {"fullname": "bpp.data.graph.annotation.node.SidechainVector.kind", "modulename": "bpp.data.graph.annotation.node", "qualname": "SidechainVector.kind", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.AnnotationKind", "default_value": "&lt;AnnotationKind.NODE: 2&gt;"}, {"fullname": "bpp.data.graph.annotation.node.SidechainVector.scale", "modulename": "bpp.data.graph.annotation.node", "qualname": "SidechainVector.scale", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "bpp.data.graph.annotation.node.SidechainVector.reverse", "modulename": "bpp.data.graph.annotation.node", "qualname": "SidechainVector.reverse", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "False"}, {"fullname": "bpp.data.graph.annotation.node.SidechainVector.default_args", "modulename": "bpp.data.graph.annotation.node", "qualname": "SidechainVector.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;scale&#x27;: True, &#x27;reverse&#x27;: False}"}, {"fullname": "bpp.data.graph.annotation.node.NodeAngle", "modulename": "bpp.data.graph.annotation.node", "qualname": "NodeAngle", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.GraphOperator"}, {"fullname": "bpp.data.graph.annotation.node.NodeAngle.__init__", "modulename": "bpp.data.graph.annotation.node", "qualname": "NodeAngle.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">name_vec_i</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">name_vec_j</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "bpp.data.graph.annotation.node.NodeAngle.name_vec_i", "modulename": "bpp.data.graph.annotation.node", "qualname": "NodeAngle.name_vec_i", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.node.NodeAngle.name_vec_j", "modulename": "bpp.data.graph.annotation.node", "qualname": "NodeAngle.name_vec_j", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.node.LigandDistances", "modulename": "bpp.data.graph.annotation.node", "qualname": "LigandDistances", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.GraphOperator"}, {"fullname": "bpp.data.graph.annotation.node.LigandDistances.__init__", "modulename": "bpp.data.graph.annotation.node", "qualname": "LigandDistances.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;ligand_distances&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">store_names_as</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;ligand_names&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">exclude_waters</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "bpp.data.graph.annotation.node.LigandDistances.store_names_as", "modulename": "bpp.data.graph.annotation.node", "qualname": "LigandDistances.store_names_as", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.node.LigandDistances.exclude_waters", "modulename": "bpp.data.graph.annotation.node", "qualname": "LigandDistances.exclude_waters", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.annotation.node.SurfaceDistance", "modulename": "bpp.data.graph.annotation.node", "qualname": "SurfaceDistance", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.GraphOperator"}, {"fullname": "bpp.data.graph.annotation.node.SurfaceDistance.__init__", "modulename": "bpp.data.graph.annotation.node", "qualname": "SurfaceDistance.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;surface_distance&#39;</span></span>)</span>"}, {"fullname": "bpp.data.graph.construction", "modulename": "bpp.data.graph.construction", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.construction.edge", "modulename": "bpp.data.graph.construction.edge", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.construction.edge.AromaticSulphur", "modulename": "bpp.data.graph.construction.edge", "qualname": "AromaticSulphur", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.AromaticSulphur.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "AromaticSulphur.function", "kind": "function", "doc": "<p>Find all aromatic-sulphur interactions.</p>\n\n<p>Criteria: Sulphur containing residue () within 5.3 Angstroms of an aromatic\nresidue ().</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>G</strong>:  The graph to add the aromatic-sulphur interactions to.</li>\n<li><strong>rgroup_df</strong>:  The rgroup dataframe. If <code>None</code> (default), the graph's\nrgroup dataframe is used.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">rgroup_df</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.AromaticSulphur.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "AromaticSulphur.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;aromatic_sulphur&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.AromaticSulphur.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "AromaticSulphur.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.construction.edge.Aromatic", "modulename": "bpp.data.graph.construction.edge", "qualname": "Aromatic", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.Aromatic.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "Aromatic.function", "kind": "function", "doc": "<p>Find all aromatic-aromatic interaction.</p>\n\n<p>Criteria: phenyl ring centroids separated between 4.5A to 7A.\nPhenyl rings are present on <code>PHE, TRP, HIS, TYR</code>\n(<code>~graphein.protein.resi_atoms.AROMATIC_RESIS</code>).\nPhenyl ring atoms on these amino acids are defined by the following\natoms:</p>\n\n<ul>\n<li>PHE: CG, CD, CE, CZ</li>\n<li>TRP: CD, CE, CH, CZ</li>\n<li>HIS: CG, CD, ND, NE, CE</li>\n<li>TYR: CG, CD, CE, CZ</li>\n</ul>\n\n<h6 id=\"centroids-of-these-atoms-are-taken-by-taking\">Centroids of these atoms are taken by taking:</h6>\n\n<blockquote>\n  <p>(mean x), (mean y), (mean z)</p>\n</blockquote>\n\n<p>for each of the ring atoms.\nNotes for future self/developers:</p>\n\n<ul>\n<li>Because of the requirement to pre-compute ring centroids, we do not\nuse the functions written above (filter_dataframe, compute_distmat,\nget_interacting_atoms), as they do not return centroid atom\neuclidean coordinates.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">pdb_df</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.Aromatic.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "Aromatic.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;aromatic&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.Aromatic.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "Aromatic.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.construction.edge.CationPi", "modulename": "bpp.data.graph.construction.edge", "qualname": "CationPi", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.CationPi.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "CationPi.function", "kind": "function", "doc": "<p>Add cation-pi interactions.</p>\n\n<h6 id=\"criteria\">Criteria:</h6>\n\n<blockquote>\n  <h1 id=\"todo\">Todo</h1>\n</blockquote>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>G</strong>:  Graph to add cation-pi interactions to.</li>\n<li><strong>rgroup_df</strong>:  Dataframe containing rgroup information. Defaults to\n<code>None</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">rgroup_df</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.CationPi.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "CationPi.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;cation_pi&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.CationPi.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "CationPi.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.construction.edge.Covalent", "modulename": "bpp.data.graph.construction.edge", "qualname": "Covalent", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.Covalent.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "Covalent.function", "kind": "function", "doc": "<p>Computes covalent edges based on atomic distances. Covalent radii are\nassigned to each atom based on its bond assign_bond_states_to_dataframe.\nThe distance matrix is then thresholded to entries less than this distance\nplus some tolerance to create an adjacency matrix. This adjacency matrix is\nthen parsed into an edge list and covalent edges added</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>G</strong>:  Atomic graph (nodes correspond to atoms) to populate with atomic\nbonds as edges</li>\n<li><strong>tolerance</strong>:  Tolerance for atomic distance. Default is <code>0.56</code>\nAngstroms. Commonly used values are: <code>0.4, 0.45, 0.56</code></li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Atomic graph with edges between bonded atoms added</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.56</span></span><span class=\"return-annotation\">) -> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.Covalent.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "Covalent.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;covalent&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.Covalent.tolerance", "modulename": "bpp.data.graph.construction.edge", "qualname": "Covalent.tolerance", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float", "default_value": "0.56"}, {"fullname": "bpp.data.graph.construction.edge.Covalent.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "Covalent.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;tolerance&#x27;: 0.56}"}, {"fullname": "bpp.data.graph.construction.edge.Delaunay", "modulename": "bpp.data.graph.construction.edge", "qualname": "Delaunay", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.Delaunay.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "Delaunay.function", "kind": "function", "doc": "<p>Compute the Delaunay triangulation of the protein structure.</p>\n\n<p>This has been used in prior work. References:</p>\n\n<pre><code>Harrison, R. W., Yu, X. &amp; Weber, I. T. Using triangulation to include\ntarget structure improves drug resistance prediction accuracy. in 1\u20131\n(IEEE, 2013). doi:10.1109/ICCABS.2013.6629236\n\nYu, X., Weber, I. T. &amp; Harrison, R. W. Prediction of HIV drug\nresistance from genotype with encoded three-dimensional protein\nstructure. BMC Genomics 15 Suppl 5, S1 (2014).\n</code></pre>\n\n<p>Notes:</p>\n\n<ol>\n<li>We do not use the add_interacting_resis function, because this\ninteraction is computed on the <code>CA</code> atoms. Therefore, there is code\nduplication. For now, I have chosen to leave this code duplication\nin.</li>\n</ol>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>G</strong>:  The networkx graph to add the triangulation to.</li>\n<li><strong>allowable_nodes</strong>:  The nodes to include in the triangulation.\nIf <code>None</code> (default), no filtering is done. This parameter is used to\nfilter out nodes that are not desired in the triangulation. Eg if you\nwanted to construct a delaunay triangulation of the CA atoms of an\natomic graph.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">allowable_nodes</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.Delaunay.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "Delaunay.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;delaunay&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.Delaunay.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "Delaunay.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.construction.edge.Disulfide", "modulename": "bpp.data.graph.construction.edge", "qualname": "Disulfide", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.Disulfide.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "Disulfide.function", "kind": "function", "doc": "<p>Find all disulfide interactions between CYS residues\n(<code>~graphein.protein.resi_atoms.DISULFIDE_RESIS</code>,\n<code>~graphein.protein.resi_atoms.DISULFIDE_ATOMS</code>).</p>\n\n<p>Criteria: sulfur atom pairs are within 2.2A of each other.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>G</strong>:  networkx protein graph</li>\n<li><strong>rgroup_df</strong>:  pd.DataFrame containing rgroup data, defaults to <code>None</code>,\nwhich retrieves the df from the provided nx graph.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">rgroup_df</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.Disulfide.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "Disulfide.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;disulfide&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.Disulfide.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "Disulfide.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.construction.edge.HydrogenBond", "modulename": "bpp.data.graph.construction.edge", "qualname": "HydrogenBond", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.HydrogenBond.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "HydrogenBond.function", "kind": "function", "doc": "<p>Add all hydrogen-bond interactions.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">rgroup_df</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.HydrogenBond.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "HydrogenBond.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;hbond&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.HydrogenBond.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "HydrogenBond.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.construction.edge.Ionic", "modulename": "bpp.data.graph.construction.edge", "qualname": "Ionic", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.Ionic.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "Ionic.function", "kind": "function", "doc": "<p>Find all ionic interactions.</p>\n\n<p>Criteria: <code>[ARG, LYS, HIS, ASP, and GLU]</code>\n(<code>~graphein.protein.resi_atoms.IONIC_RESIS</code>) residues are within 6A.</p>\n\n<p>We also check for opposing charges\n(<code>~graphein.protein.resi_atoms.POS_AA</code>,\n<code>~graphein.protein.resi_atoms.NEG_AA</code>).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>G</strong>:  nx.Graph to add ionic interactions to.</li>\n<li><strong>rgroup_df</strong>:  Optional dataframe of R-group atoms. Default is <code>None</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">rgroup_df</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.Ionic.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "Ionic.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;ionic&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.Ionic.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "Ionic.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.construction.edge.KNN", "modulename": "bpp.data.graph.construction.edge", "qualname": "KNN", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.KNN.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "KNN.function", "kind": "function", "doc": "<p>Adds edges to nodes based on K nearest neighbours. Long interaction\nthreshold is used to specify minimum separation in sequence to add an edge\nbetween networkx nodes within the distance threshold</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>G</strong>:  Protein Structure graph to add distance edges to</li>\n<li><strong>long_interaction_threshold</strong>:  minimum distance in sequence for two\nnodes to be connected</li>\n<li><strong>k</strong>:  Number of neighbors for each sample.</li>\n<li><strong>exclude_edges</strong>:  Types of edges to exclude. Supported values are\n<code>inter</code> and <code>intra</code>.\n<ul>\n<li><code>inter</code> removes inter-connections between nodes of the same chain.</li>\n<li><code>intra</code> removes intra-connections between nodes of different chains.</li>\n</ul></li>\n<li><strong>exclude_self_loops</strong>:  Whether or not to mark each sample as the first\nnearest neighbor to itself.</li>\n<li><strong>kind_name</strong>:  Name for kind of edges in networkx graph.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Graph with knn-based edges added</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>,</span><span class=\"param\">\t<span class=\"n\">long_interaction_threshold</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">exclude_edges</span><span class=\"p\">:</span> <span class=\"n\">Iterable</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">exclude_self_loops</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">kind_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;knn&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.KNN.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "KNN.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;knn&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.KNN.long_interaction_threshold", "modulename": "bpp.data.graph.construction.edge", "qualname": "KNN.long_interaction_threshold", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "30"}, {"fullname": "bpp.data.graph.construction.edge.KNN.k", "modulename": "bpp.data.graph.construction.edge", "qualname": "KNN.k", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "10"}, {"fullname": "bpp.data.graph.construction.edge.KNN.exclude_edges", "modulename": "bpp.data.graph.construction.edge", "qualname": "KNN.exclude_edges", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Iterable[Literal[&#x27;inter&#x27;, &#x27;intra&#x27;]]", "default_value": "()"}, {"fullname": "bpp.data.graph.construction.edge.KNN.exclude_self_loops", "modulename": "bpp.data.graph.construction.edge", "qualname": "KNN.exclude_self_loops", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool", "default_value": "True"}, {"fullname": "bpp.data.graph.construction.edge.KNN.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "KNN.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;long_interaction_threshold&#x27;: 30, &#x27;k&#x27;: 10, &#x27;exclude_edges&#x27;: (), &#x27;exclude_self_loops&#x27;: True}"}, {"fullname": "bpp.data.graph.construction.edge.PeptideBond", "modulename": "bpp.data.graph.construction.edge", "qualname": "PeptideBond", "kind": "class", "doc": "<p></p>\n", "bases": "bpp.data.graph.operator.EdgeConstructorFunctionOperator"}, {"fullname": "bpp.data.graph.construction.edge.PeptideBond.function", "modulename": "bpp.data.graph.construction.edge", "qualname": "PeptideBond.function", "kind": "function", "doc": "<p>Adds peptide backbone as edges to residues in each chain.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>G</strong>:  Networkx protein graph.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Networkx protein graph with added peptide bonds.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">G</span><span class=\"p\">:</span> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span></span><span class=\"return-annotation\">) -> <span class=\"n\">networkx</span><span class=\"o\">.</span><span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">graph</span><span class=\"o\">.</span><span class=\"n\">Graph</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.data.graph.construction.edge.PeptideBond.id", "modulename": "bpp.data.graph.construction.edge", "qualname": "PeptideBond.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str", "default_value": "&#x27;peptide_bond&#x27;"}, {"fullname": "bpp.data.graph.construction.edge.PeptideBond.default_args", "modulename": "bpp.data.graph.construction.edge", "qualname": "PeptideBond.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.operator", "modulename": "bpp.data.graph.operator", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.operator.logger", "modulename": "bpp.data.graph.operator", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger bpp.data.graph.operator (WARNING)&gt;"}, {"fullname": "bpp.data.graph.operator.AnnotationKind", "modulename": "bpp.data.graph.operator", "qualname": "AnnotationKind", "kind": "class", "doc": "<p></p>\n", "bases": "enum.Enum"}, {"fullname": "bpp.data.graph.operator.AnnotationKind.NONE", "modulename": "bpp.data.graph.operator", "qualname": "AnnotationKind.NONE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;AnnotationKind.NONE: 1&gt;"}, {"fullname": "bpp.data.graph.operator.AnnotationKind.NODE", "modulename": "bpp.data.graph.operator", "qualname": "AnnotationKind.NODE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;AnnotationKind.NODE: 2&gt;"}, {"fullname": "bpp.data.graph.operator.AnnotationKind.EDGE", "modulename": "bpp.data.graph.operator", "qualname": "AnnotationKind.EDGE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;AnnotationKind.EDGE: 4&gt;"}, {"fullname": "bpp.data.graph.operator.AnnotationKind.GRAPH", "modulename": "bpp.data.graph.operator", "qualname": "AnnotationKind.GRAPH", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;AnnotationKind.GRAPH: 8&gt;"}, {"fullname": "bpp.data.graph.operator.Operator", "modulename": "bpp.data.graph.operator", "qualname": "Operator", "kind": "class", "doc": "<p></p>\n", "bases": "abc.ABC"}, {"fullname": "bpp.data.graph.operator.Operator.__init__", "modulename": "bpp.data.graph.operator", "qualname": "Operator.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "bpp.data.graph.operator.Operator.kind", "modulename": "bpp.data.graph.operator", "qualname": "Operator.kind", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.AnnotationKind", "default_value": "&lt;AnnotationKind.NONE: 1&gt;"}, {"fullname": "bpp.data.graph.operator.Operator.name", "modulename": "bpp.data.graph.operator", "qualname": "Operator.name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.operator.GraphOperator", "modulename": "bpp.data.graph.operator", "qualname": "GraphOperator", "kind": "class", "doc": "<p></p>\n", "bases": "Operator"}, {"fullname": "bpp.data.graph.operator.NodeOperator", "modulename": "bpp.data.graph.operator", "qualname": "NodeOperator", "kind": "class", "doc": "<p></p>\n", "bases": "Operator"}, {"fullname": "bpp.data.graph.operator.NodeOperator.kind", "modulename": "bpp.data.graph.operator", "qualname": "NodeOperator.kind", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.AnnotationKind", "default_value": "&lt;AnnotationKind.NODE: 2&gt;"}, {"fullname": "bpp.data.graph.operator.EdgeOperator", "modulename": "bpp.data.graph.operator", "qualname": "EdgeOperator", "kind": "class", "doc": "<p></p>\n", "bases": "Operator"}, {"fullname": "bpp.data.graph.operator.EdgeOperator.kind", "modulename": "bpp.data.graph.operator", "qualname": "EdgeOperator.kind", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.AnnotationKind", "default_value": "&lt;AnnotationKind.EDGE: 4&gt;"}, {"fullname": "bpp.data.graph.operator.GraphFunction", "modulename": "bpp.data.graph.operator", "qualname": "GraphFunction", "kind": "class", "doc": "<p></p>\n", "bases": "typing.Protocol"}, {"fullname": "bpp.data.graph.operator.GraphFunction.__init__", "modulename": "bpp.data.graph.operator", "qualname": "GraphFunction.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "bpp.data.graph.operator.NodeFunction", "modulename": "bpp.data.graph.operator", "qualname": "NodeFunction", "kind": "class", "doc": "<p></p>\n", "bases": "typing.Protocol"}, {"fullname": "bpp.data.graph.operator.NodeFunction.__init__", "modulename": "bpp.data.graph.operator", "qualname": "NodeFunction.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "bpp.data.graph.operator.EdgeFunction", "modulename": "bpp.data.graph.operator", "qualname": "EdgeFunction", "kind": "class", "doc": "<p></p>\n", "bases": "typing.Protocol"}, {"fullname": "bpp.data.graph.operator.EdgeFunction.__init__", "modulename": "bpp.data.graph.operator", "qualname": "EdgeFunction.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span>)</span>"}, {"fullname": "bpp.data.graph.operator.FunctionOperatorMetaClass", "modulename": "bpp.data.graph.operator", "qualname": "FunctionOperatorMetaClass", "kind": "class", "doc": "<p></p>\n", "bases": "abc.ABCMeta"}, {"fullname": "bpp.data.graph.operator.FunctionOperator", "modulename": "bpp.data.graph.operator", "qualname": "FunctionOperator", "kind": "class", "doc": "<p></p>\n", "bases": "Operator"}, {"fullname": "bpp.data.graph.operator.FunctionOperator.__init__", "modulename": "bpp.data.graph.operator", "qualname": "FunctionOperator.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">extra_args</span><span class=\"p\">:</span> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "bpp.data.graph.operator.FunctionOperator.function", "modulename": "bpp.data.graph.operator", "qualname": "FunctionOperator.function", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Callable[..., NoneType]"}, {"fullname": "bpp.data.graph.operator.FunctionOperator.id", "modulename": "bpp.data.graph.operator", "qualname": "FunctionOperator.id", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "bpp.data.graph.operator.FunctionOperator.extra_args", "modulename": "bpp.data.graph.operator", "qualname": "FunctionOperator.extra_args", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.graph.operator.FunctionOperator.default_args", "modulename": "bpp.data.graph.operator", "qualname": "FunctionOperator.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.operator.EdgeConstructorFunctionOperator", "modulename": "bpp.data.graph.operator", "qualname": "EdgeConstructorFunctionOperator", "kind": "class", "doc": "<p></p>\n", "bases": "FunctionOperator, GraphOperator"}, {"fullname": "bpp.data.graph.operator.EdgeConstructorFunctionOperator.function", "modulename": "bpp.data.graph.operator", "qualname": "EdgeConstructorFunctionOperator.function", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.GraphFunction"}, {"fullname": "bpp.data.graph.operator.EdgeConstructorFunctionOperator.default_args", "modulename": "bpp.data.graph.operator", "qualname": "EdgeConstructorFunctionOperator.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.operator.GraphAnnotationFunctionOperator", "modulename": "bpp.data.graph.operator", "qualname": "GraphAnnotationFunctionOperator", "kind": "class", "doc": "<p></p>\n", "bases": "FunctionOperator, GraphOperator"}, {"fullname": "bpp.data.graph.operator.GraphAnnotationFunctionOperator.function", "modulename": "bpp.data.graph.operator", "qualname": "GraphAnnotationFunctionOperator.function", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.GraphFunction"}, {"fullname": "bpp.data.graph.operator.GraphAnnotationFunctionOperator.default_args", "modulename": "bpp.data.graph.operator", "qualname": "GraphAnnotationFunctionOperator.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.operator.NodeAnnotationFunctionOperator", "modulename": "bpp.data.graph.operator", "qualname": "NodeAnnotationFunctionOperator", "kind": "class", "doc": "<p></p>\n", "bases": "FunctionOperator, NodeOperator"}, {"fullname": "bpp.data.graph.operator.NodeAnnotationFunctionOperator.function", "modulename": "bpp.data.graph.operator", "qualname": "NodeAnnotationFunctionOperator.function", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.NodeFunction"}, {"fullname": "bpp.data.graph.operator.NodeAnnotationFunctionOperator.default_args", "modulename": "bpp.data.graph.operator", "qualname": "NodeAnnotationFunctionOperator.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.graph.operator.EdgeAnnotationFunctionOperator", "modulename": "bpp.data.graph.operator", "qualname": "EdgeAnnotationFunctionOperator", "kind": "class", "doc": "<p></p>\n", "bases": "FunctionOperator, EdgeOperator"}, {"fullname": "bpp.data.graph.operator.EdgeAnnotationFunctionOperator.function", "modulename": "bpp.data.graph.operator", "qualname": "EdgeAnnotationFunctionOperator.function", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bpp.data.graph.operator.EdgeFunction"}, {"fullname": "bpp.data.graph.operator.EdgeAnnotationFunctionOperator.default_args", "modulename": "bpp.data.graph.operator", "qualname": "EdgeAnnotationFunctionOperator.default_args", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "bpp.data.transform", "modulename": "bpp.data.transform", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.data.transform.Sequential", "modulename": "bpp.data.transform", "qualname": "Sequential", "kind": "class", "doc": "<p>Run multiple transformation in sequence.</p>\n"}, {"fullname": "bpp.data.transform.Sequential.__init__", "modulename": "bpp.data.transform", "qualname": "Sequential.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>transforms:</strong>  List of transformations.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">transforms</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span><span class=\"p\">],</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span><span class=\"p\">]]</span></span>)</span>"}, {"fullname": "bpp.data.transform.Sequential.transforms", "modulename": "bpp.data.transform", "qualname": "Sequential.transforms", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.transform.ConcatenateFeatures", "modulename": "bpp.data.transform", "qualname": "ConcatenateFeatures", "kind": "class", "doc": "<p>Concatenate extra node and edge attributes with their respective default\nfeature attributes.</p>\n\n<p><strong>Note</strong>: deletes the original node and edge attributes.</p>\n"}, {"fullname": "bpp.data.transform.ConcatenateFeatures.__init__", "modulename": "bpp.data.transform", "qualname": "ConcatenateFeatures.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>node:</strong>  Attribute names of features that should be added to default\nnode features.</li>\n<li><strong>edge:</strong>  Attribute names of features that should be added to default\nedge features.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">node</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">edge</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "bpp.data.transform.ConcatenateFeatures.node", "modulename": "bpp.data.transform", "qualname": "ConcatenateFeatures.node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.transform.ConcatenateFeatures.edge", "modulename": "bpp.data.transform", "qualname": "ConcatenateFeatures.edge", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.data.transform.CollapseTargets", "modulename": "bpp.data.transform", "qualname": "CollapseTargets", "kind": "class", "doc": "<p>Collapses binding-site targets.</p>\n\n<p>A protein can have multiple binding-sites; this transformation collapses\nthe multi-dimensional binding-site tensor into a one-dimensional tensor.</p>\n"}, {"fullname": "bpp.loss", "modulename": "bpp.loss", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.loss.focal_tversky_loss", "modulename": "bpp.loss", "qualname": "focal_tversky_loss", "kind": "function", "doc": "<p>Focal Tversky Loss.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>p:</strong>  Predicted probabilities.</li>\n<li><strong>t:</strong>  Binary targets.</li>\n<li><strong>w:</strong>  Sample weights.</li>\n<li><strong>alpha:</strong>  False-positive weight.</li>\n<li><strong>beta:</strong>  False-negative weight.</li>\n<li><strong>gamma:</strong>  Focal scaling exponent.</li>\n<li><strong>smooth:</strong>  Smoothing coefficient.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Loss between <code>p</code> and <code>t</code>.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">p</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">t</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">w</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.7</span>,</span><span class=\"param\">\t<span class=\"n\">beta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.3</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.3333333333333333</span>,</span><span class=\"param\">\t<span class=\"n\">smooth</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.loss.FocalTverskyLoss", "modulename": "bpp.loss", "qualname": "FocalTverskyLoss", "kind": "class", "doc": "<p>Focal Tversky Loss.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.loss.FocalTverskyLoss.__init__", "modulename": "bpp.loss", "qualname": "FocalTverskyLoss.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>alpha:</strong>  False-positive weight.</li>\n<li><strong>beta:</strong>  False-negative weight.</li>\n<li><strong>gamma:</strong>  Focal scaling exponent.</li>\n<li><strong>smooth:</strong>  Smoothing coefficient.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.7</span>,</span><span class=\"param\">\t<span class=\"n\">beta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.3</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.3333333333333333</span>,</span><span class=\"param\">\t<span class=\"n\">smooth</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mi\">1</span></span>)</span>"}, {"fullname": "bpp.loss.FocalTverskyLoss.alpha", "modulename": "bpp.loss", "qualname": "FocalTverskyLoss.alpha", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.loss.FocalTverskyLoss.beta", "modulename": "bpp.loss", "qualname": "FocalTverskyLoss.beta", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.loss.FocalTverskyLoss.gamma", "modulename": "bpp.loss", "qualname": "FocalTverskyLoss.gamma", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.loss.FocalTverskyLoss.smooth", "modulename": "bpp.loss", "qualname": "FocalTverskyLoss.smooth", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.loss.FocalTverskyLoss.forward", "modulename": "bpp.loss", "qualname": "FocalTverskyLoss.forward", "kind": "function", "doc": "<p>Compute loss.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>p:</strong>  Predicted probabilities.</li>\n<li><strong>t:</strong>  Binary targets.</li>\n<li><strong>w:</strong>  Sample weights.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Loss between <code>p</code> and <code>t</code>.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">p</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">t</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">w</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model", "modulename": "bpp.model", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "bpp.model.logger", "modulename": "bpp.model", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger bpp.model (WARNING)&gt;"}, {"fullname": "bpp.model.StandardizeFeatures", "modulename": "bpp.model", "qualname": "StandardizeFeatures", "kind": "class", "doc": "<p>Standardize features in geometric data object.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.StandardizeFeatures.__init__", "modulename": "bpp.model", "qualname": "StandardizeFeatures.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>stats_path:</strong>  YAML file containing mean and standard deviation for\nfeatures that should be standardized.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">stats_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "bpp.model.StandardizeFeatures.stats", "modulename": "bpp.model", "qualname": "StandardizeFeatures.stats", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.StandardizeFeatures.forward", "modulename": "bpp.model", "qualname": "StandardizeFeatures.forward", "kind": "function", "doc": "<p>Standardize features.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>data:</strong>  Geometric data object.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Geometric data object with standardized features.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.ResidueEmbedding", "modulename": "bpp.model", "qualname": "ResidueEmbedding", "kind": "class", "doc": "<p>Computes residue embeddings and adds them to the node features.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.ResidueEmbedding.__init__", "modulename": "bpp.model", "qualname": "ResidueEmbedding.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>num_embeddings:</strong>  Number of embeddings.</li>\n<li><strong>embedding_dim:</strong>  Desired embedding dimension.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">num_embeddings</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>, </span><span class=\"param\"><span class=\"n\">embedding_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">12</span></span>)</span>"}, {"fullname": "bpp.model.ResidueEmbedding.embed", "modulename": "bpp.model", "qualname": "ResidueEmbedding.embed", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.ResidueEmbedding.forward", "modulename": "bpp.model", "qualname": "ResidueEmbedding.forward", "kind": "function", "doc": "<p>Compute residue embeddings and add them to the node feautres.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>data:</strong>  Geometric data object.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Geometric data object with residue embeddings added to the node\n  features.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.ElementEmbedding", "modulename": "bpp.model", "qualname": "ElementEmbedding", "kind": "class", "doc": "<p>Computes element embeddings and adds them to the node features.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.ElementEmbedding.__init__", "modulename": "bpp.model", "qualname": "ElementEmbedding.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>num_embeddings:</strong>  Number of embeddings.</li>\n<li><strong>embedding_dim:</strong>  Desired embedding dimension.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">num_embeddings</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>, </span><span class=\"param\"><span class=\"n\">embedding_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">4</span></span>)</span>"}, {"fullname": "bpp.model.ElementEmbedding.embed", "modulename": "bpp.model", "qualname": "ElementEmbedding.embed", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.ElementEmbedding.forward", "modulename": "bpp.model", "qualname": "ElementEmbedding.forward", "kind": "function", "doc": "<p>Compute element features and add them to the node features.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>data:</strong>  Geometric data object.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Geometric data object with element embeddings added to the node\n  features.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.LinearTransformNode", "modulename": "bpp.model", "qualname": "LinearTransformNode", "kind": "class", "doc": "<p>Linear transform node features.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.LinearTransformNode.__init__", "modulename": "bpp.model", "qualname": "LinearTransformNode.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>in_features:</strong>  Number of input node features.</li>\n<li><strong>out_features:</strong>  Number of output node features.</li>\n<li><strong>bias:</strong>  Whether bias should be added to linear transformation.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">out_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "bpp.model.LinearTransformNode.linear", "modulename": "bpp.model", "qualname": "LinearTransformNode.linear", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.LinearTransformNode.forward", "modulename": "bpp.model", "qualname": "LinearTransformNode.forward", "kind": "function", "doc": "<p>Linear transform node features.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>data:</strong>  Geometric data object.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Geometric data object with linear transformed node features.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.LinearTransformEdge", "modulename": "bpp.model", "qualname": "LinearTransformEdge", "kind": "class", "doc": "<p>Linear transform edge features.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.LinearTransformEdge.__init__", "modulename": "bpp.model", "qualname": "LinearTransformEdge.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>in_features:</strong>  Number of input edge features.</li>\n<li><strong>out_features:</strong>  Number of output edge features.</li>\n<li><strong>bias:</strong>  Whether bias should be added to linear transformation.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">in_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">out_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "bpp.model.LinearTransformEdge.linear", "modulename": "bpp.model", "qualname": "LinearTransformEdge.linear", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.LinearTransformEdge.forward", "modulename": "bpp.model", "qualname": "LinearTransformEdge.forward", "kind": "function", "doc": "<p>Linear transform edge features.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>data:</strong>  Geometric data object.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Geometric data object with linear transformed edge features.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule", "modulename": "bpp.model", "qualname": "GeometricModule", "kind": "class", "doc": "<p>Generic lightning module for geometric models.</p>\n", "bases": "pytorch_lightning.core.module.LightningModule"}, {"fullname": "bpp.model.GeometricModule.__init__", "modulename": "bpp.model", "qualname": "GeometricModule.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>tail:</strong>  Tail model configuration.</li>\n<li><strong>body:</strong>  Body model configuration.</li>\n<li><strong>head:</strong>  Head model configuration.</li>\n<li><strong>loss:</strong>  Loss configuration.</li>\n<li><strong>metrics:</strong>  Metrics configuration.</li>\n<li><strong>optimizer:</strong>  Optimizer configuration.</li>\n<li><strong>scheduler:</strong>  Learning-rate scheduler configuration.</li>\n<li><strong>example_input:</strong>  Example input.</li>\n<li><strong>log_net_stats:</strong>  Which network statistics to log:\n<ul>\n<li><code>\"grad_norms\"</code>: Gradient norms.</li>\n<li><code>\"weight_stats\"</code>: Mean and standard deviation of weights.</li>\n<li><code>\"pos_coef\"</code>: Scale and exponent for positional updates.</li>\n</ul></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">tail</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>,</span><span class=\"param\">\t<span class=\"n\">body</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>,</span><span class=\"param\">\t<span class=\"n\">head</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>,</span><span class=\"param\">\t<span class=\"n\">loss</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>,</span><span class=\"param\">\t<span class=\"n\">metrics</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>,</span><span class=\"param\">\t<span class=\"n\">optimizer</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>,</span><span class=\"param\">\t<span class=\"n\">scheduler</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">example_input</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">log_net_stats</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Literal</span><span class=\"p\">[</span><span class=\"s1\">&#39;grad_norm&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;weight_stat&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;pos_coef&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;deq_abs&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;deq_rel&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;deq_nstep&#39;</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">[]</span></span>)</span>"}, {"fullname": "bpp.model.GeometricModule.tail", "modulename": "bpp.model", "qualname": "GeometricModule.tail", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.body", "modulename": "bpp.model", "qualname": "GeometricModule.body", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.head", "modulename": "bpp.model", "qualname": "GeometricModule.head", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.loss", "modulename": "bpp.model", "qualname": "GeometricModule.loss", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.train_metrics", "modulename": "bpp.model", "qualname": "GeometricModule.train_metrics", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.val_metrics", "modulename": "bpp.model", "qualname": "GeometricModule.val_metrics", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.test_metrics", "modulename": "bpp.model", "qualname": "GeometricModule.test_metrics", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.misc_metrics", "modulename": "bpp.model", "qualname": "GeometricModule.misc_metrics", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.optimizer", "modulename": "bpp.model", "qualname": "GeometricModule.optimizer", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.scheduler", "modulename": "bpp.model", "qualname": "GeometricModule.scheduler", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.example_input_array", "modulename": "bpp.model", "qualname": "GeometricModule.example_input_array", "kind": "variable", "doc": "<p>The example input array is a specification of what the module can consume in the <code>forward()</code> method. The\nreturn type is interpreted as follows:</p>\n\n<ul>\n<li>Single tensor: It is assumed the model takes a single argument, i.e.,\n<code>model.forward(model.example_input_array)</code></li>\n<li>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,\n<code>model.forward(*model.example_input_array)</code></li>\n<li>Dict: The input array represents named keyword arguments, i.e.,\n<code>model.forward(**model.example_input_array)</code></li>\n</ul>\n", "annotation": ": Union[torch.Tensor, Tuple, Dict, NoneType]"}, {"fullname": "bpp.model.GeometricModule.log_net_stats", "modulename": "bpp.model", "qualname": "GeometricModule.log_net_stats", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.GeometricModule.forward", "modulename": "bpp.model", "qualname": "GeometricModule.forward", "kind": "function", "doc": "<p>Compute forward pass.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>data:</strong>  Model input.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Logits.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule.compute", "modulename": "bpp.model", "qualname": "GeometricModule.compute", "kind": "function", "doc": "<p>Compute probabilities.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>batch:</strong>  Data batch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Predicted probabilities, targets, optional penalty and info\n  dictionary containing metrics generated by sub-optimizers.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule.training_step", "modulename": "bpp.model", "qualname": "GeometricModule.training_step", "kind": "function", "doc": "<p>Compute probabilities, loss and metrics.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>batch:</strong>  Data batch.</li>\n<li><strong>batch_idx:</strong>  Index of batch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Loss.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>,</span><span class=\"param\">\t<span class=\"n\">batch_idx</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule.validation_step", "modulename": "bpp.model", "qualname": "GeometricModule.validation_step", "kind": "function", "doc": "<p>Update validation metrics.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>batch:</strong>  Data batch.</li>\n<li><strong>batch_idx:</strong>  Index of batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule.on_validation_epoch_end", "modulename": "bpp.model", "qualname": "GeometricModule.on_validation_epoch_end", "kind": "function", "doc": "<p>Compute and log validation metrics.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule.test_step", "modulename": "bpp.model", "qualname": "GeometricModule.test_step", "kind": "function", "doc": "<p>Update test metrics.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>batch:</strong>  Data batch.</li>\n<li><strong>batch_idx:</strong>  Index of batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Data</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule.on_test_epoch_end", "modulename": "bpp.model", "qualname": "GeometricModule.on_test_epoch_end", "kind": "function", "doc": "<p>Compute and log test metrics.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule.configure_optimizers", "modulename": "bpp.model", "qualname": "GeometricModule.configure_optimizers", "kind": "function", "doc": "<p>Configure optimizer.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple with list containing one optimizer and a list that is either\n  empty or that contains one learning-rate scheduler.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"nb\">list</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.GeometricModule.on_before_optimizer_step", "modulename": "bpp.model", "qualname": "GeometricModule.on_before_optimizer_step", "kind": "function", "doc": "<p>Log model statistics.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>optimizer:</strong>  Optimizer that is currently used.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">optimizer</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">Optimizer</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn", "modulename": "bpp.model.egnn", "kind": "module", "doc": "<p>Module containing implementations of E(n) Equivariant Graph Neural Networks.</p>\n\n<h6 id=\"references\">References:</h6>\n\n<blockquote>\n  <p>[^1]: Victor Garcia Satorras, , Emiel Hoogeboom, and Max Welling. \"E(n)\n         Equivariant Graph Neural Networks.\" (2022).\n         <code>arXiv:2102.09844&lt;https://arxiv.org/abs/2102.09844&gt;</code>.</p>\n</blockquote>\n"}, {"fullname": "bpp.model.egnn.parameter_init", "modulename": "bpp.model.egnn", "qualname": "parameter_init", "kind": "function", "doc": "<p>Initialize module parameters. Uses kaiming initialization for linear\nmodules and sets parameters of other modules accordingly.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>module:</strong>  Module that parameters should be initialized.</li>\n<li><strong>nonlinearity:</strong>  Nonlinearity that should be assumed for linear modules.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">module</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">nonlinearity</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;relu&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.iter_net_segments", "modulename": "bpp.model.egnn", "qualname": "iter_net_segments", "kind": "function", "doc": "<p>Initializes and yields individual segments for feed-forward networks.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>dims:</strong>  Dimensions for input, hidden and output features.</li>\n<li><strong>norm:</strong>  Whether to layer-normalize inputs.</li>\n<li><strong>clamp:</strong>  Threshold for clamping the output (between <code>-clamp</code> and\n<code>clamp</code>).  Unclamped if <code>clamp &lt;= 0</code>.</li>\n<li><strong>dropout:</strong>  Dropout probability in-between layers of network. No\ndropout if <code>0</code>.</li>\n<li><strong>activation:</strong>  Activation function that is used in-between network\nlayers.</li>\n<li><strong>norm_cls:</strong>  Normalization module class instance.</li>\n<li><strong>dropout_cls:</strong>  Dropout module class instance.</li>\n</ul>\n\n<h6 id=\"yields\">Yields:</h6>\n\n<blockquote>\n  <p>Individual segments of network.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">dims</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.batchnorm.BatchNorm1d&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;</span><span class=\"return-annotation\">) -> <span class=\"n\">Iterable</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.init_net_segments", "modulename": "bpp.model.egnn", "qualname": "init_net_segments", "kind": "function", "doc": "<p>Initialize sequence of network segments.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>init:</strong>  Initializer that is used for network layers. First argument is\nthe module that should be initialized, the second is the\nnon-linearity, in case of a linear module, that should be used.\nDefault non-linearity must be set.</li>\n<li><strong>sequence:</strong>  Sequence of network segments.</li>\n<li><strong>head_nonlinearity:</strong>  Non-linearity for head of network.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">sequence</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">head_nonlinearity</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.fourier_encode", "modulename": "bpp.model.egnn", "qualname": "fourier_encode", "kind": "function", "doc": "<p>Encodes <code>x</code> to be represented by a vector of fourier features.</p>\n\n<p>Depending on whether <code>num</code> is even or odd, the vector of encoded features\nwill also contain <code>x</code> itself: if even, <code>x</code> is not included, if odd <code>x</code> is\nincluded.</p>\n\n<p>Assuming <code>num</code> is odd, the features \\( y \\) look as follows:</p>\n\n<p>$$\\begin{aligned}\ns_k &amp;= x \\cdot 0.5^k \\\\\n\\mathbf{y} &amp;= \\left[\\sin(s_0), \\dots, \\sin(s_{\\lfloor\\text{num}/2\\rfloor-1}),\n                    \\cos(s_0), \\dots, \\cos(s_{\\lfloor\\text{num}/2\\rfloor-1}), x\\right]\n\\end{aligned}$$</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Value from which the fourier features should be computed.</li>\n<li><strong>num:</strong>  Number of fourier features that should be computed.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Fourier features of <code>x</code>.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">num</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.Apply", "modulename": "bpp.model.egnn", "qualname": "Apply", "kind": "class", "doc": "<p>Apply Module.</p>\n\n<p>Applies <code>fn()</code> to an input and returns the result.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.egnn.Apply.__init__", "modulename": "bpp.model.egnn", "qualname": "Apply.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>fn:</strong>  Function that should be applied.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">fn</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">Any</span><span class=\"p\">],</span> <span class=\"n\">Any</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "bpp.model.egnn.Apply.fn", "modulename": "bpp.model.egnn", "qualname": "Apply.fn", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.Apply.extra_repr", "modulename": "bpp.model.egnn", "qualname": "Apply.extra_repr", "kind": "function", "doc": "<p>Returns the representation of <code>fn()</code>.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Representation of <code>fn()</code>.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.Apply.forward", "modulename": "bpp.model.egnn", "qualname": "Apply.forward", "kind": "function", "doc": "<p>Call <code>fn()</code> on <code>input</code> and return result.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Input for <code>fn()</code>.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Result of <code>fn(input)</code>.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">Any</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Any</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.EGNN", "modulename": "bpp.model.egnn", "qualname": "EGNN", "kind": "class", "doc": "<p>E(n) Equivariant Graph Neural Network.</p>\n\n<p>Implementation of an E(n) Equivariant Graph Neural Network as described in\n[1]_ that supports multiple node coordinates. This way we can encode\ndifferent spatial features as coordinate; e.g., vectors that originate from\na single node.</p>\n\n<p>Node features are usually two-dimensional tensors of the size \\( (N, F) \\),\nwith \\( N \\) being the number of nodes and \\( F \\) the number of\nfeatures.</p>\n\n<p>Similarly, coordinates have the size \\( (N, D) \\) with \\( D \\) being the\ndimension of the coordinate space. Alternatively, to encode multiple\ncoordinates per node, the coordinates can be \\( (N, C, D) \\) with\n\\( C \\) as the number of individual coordinates per node.</p>\n\n<p>Edge features are optional and have the size \\( (E, G) \\) with \\( E \\)\nas the number of edges and \\( G \\) as the number of edge features.</p>\n\n<h6 id=\"example\">Example:</h6>\n\n<blockquote>\n  <p>EGNN instance with 16 input and 32 output features and two coordinates\n  per node.</p>\n  \n  <div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">bpp.model.egnn</span> <span class=\"kn\">import</span> <span class=\"n\">EGNN</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fn</span> <span class=\"o\">=</span> <span class=\"n\">EGNN</span><span class=\"p\">(</span>\n<span class=\"gp\">... </span>    <span class=\"n\">dims_node</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">),</span>\n<span class=\"gp\">... </span>    <span class=\"n\">dims_edge</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">),</span>\n<span class=\"gp\">... </span>    <span class=\"n\">dims_pos</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,),</span>\n<span class=\"gp\">... </span>    <span class=\"n\">num_pos</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n<span class=\"go\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fn</span>\n<span class=\"go\">EGNN(</span>\n<span class=\"go\">  (aggr_mean): MeanAggregation()</span>\n<span class=\"go\">  (aggr_sum): SumAggregation()</span>\n<span class=\"go\">  (edge_net): Sequential(</span>\n<span class=\"go\">    (0): Linear(in_features=34, out_features=64, bias=True)</span>\n<span class=\"go\">    (1): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">    (2): Linear(in_features=64, out_features=16, bias=True)</span>\n<span class=\"go\">    (3): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">  )</span>\n<span class=\"go\">  (node_net): Sequential(</span>\n<span class=\"go\">    (0): Linear(in_features=32, out_features=64, bias=True)</span>\n<span class=\"go\">    (1): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">    (2): Linear(in_features=64, out_features=32, bias=True)</span>\n<span class=\"go\">  )</span>\n<span class=\"go\">  (pos_net): Sequential(</span>\n<span class=\"go\">    (0): Linear(in_features=16, out_features=32, bias=True)</span>\n<span class=\"go\">    (1): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">    (2): Linear(in_features=32, out_features=2, bias=True)</span>\n<span class=\"go\">  )</span>\n<span class=\"go\">)</span>\n</code></pre>\n  </div>\n</blockquote>\n", "bases": "torch_geometric.nn.conv.message_passing.MessagePassing"}, {"fullname": "bpp.model.egnn.EGNN.__init__", "modulename": "bpp.model.egnn", "qualname": "EGNN.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>dims_node:</strong>  Dimensions for the node network: <code>dims_node[0]</code> is the\nnumber of input features and <code>dims_node[-1]</code> is the number of\noutput features.  At least 2 dimensions are required. All\nremaining dimensions are used for the hidden-layers of the\nnetwork.</li>\n<li><strong>dims_edge:</strong>  Dimensions for the edge network: <code>dims_edge[0]</code> is the\nnumber of edge features (0 if graphs have no edge features),\n<code>dims_edge[-1]</code> is the number of message features.  All\nremaining dimensions are used for the hidden-layers of the edge\nnetwork that computes the messages.</li>\n<li><strong>dims_gate:</strong>  Dimensions for the message gating network. If empty,\nno message gating network will be created and message gating\nwill be disabled.</li>\n<li><strong>dims_pos:</strong>  Dimensions for the coordinate update network. If empty,\nno coordinate update network will be created and coordinate\nupdates will be disabled.</li>\n<li><strong>num_pos:</strong>  Number of node positions. Each node can be assigned to one\nposition, but can also be assigned to multiple positions.</li>\n<li><strong>num_encode:</strong>  Number of fourier-encoded features that are computed\nfrom the distances between node coordinates. If <code>num_encode</code> is\neven, only the fourier-encoded features will be used. If odd,\nthe original distances will also be used alongside the\nfourier-encoded features.  Default is 1, which means that only\nthe original distances are used, without any fourier features.</li>\n<li><strong>pos_scale:</strong>  Initial scaler for coordinate updates. If pos_scale is\n0, the penultimate layer of the coordinate update network will\nuse a linear activation and omit the scaling factor.</li>\n<li><strong>norm:</strong>  Whether to use layer and message normalization while computing\nand aggregating messages.</li>\n<li><strong>clamp:</strong>  Threshold for clamping coordinate updates (between <code>-clamp</code>\nand <code>clamp</code>). Unclamped if 0.</li>\n<li><strong>dropout:</strong>  Dropout probability in-between network layers. No dropout\nif 0.</li>\n<li><strong>activation:</strong>  Activation function that is used in-between network\nlayers.</li>\n<li><strong>init:</strong>  Initializer that is used for network layers. First argument is\nthe module that should be initialized, the second is the\nnon-linearity, in case of a linear module, that should be used.\nThe default non-linearity should adhere to whatever is used for\n<code>activation</code>. See <code>parameter_init()</code>.</li>\n<li><strong>norm_cls:</strong>  Class instance of normalization module.</li>\n<li><strong>dropout_cls:</strong>  Class instance of dropout module.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.batchnorm.BatchNorm1d&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;</span>)</span>"}, {"fullname": "bpp.model.egnn.EGNN.aggr_mean", "modulename": "bpp.model.egnn", "qualname": "EGNN.aggr_mean", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.aggr_sum", "modulename": "bpp.model.egnn", "qualname": "EGNN.aggr_sum", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.dims_node", "modulename": "bpp.model.egnn", "qualname": "EGNN.dims_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.dims_edge", "modulename": "bpp.model.egnn", "qualname": "EGNN.dims_edge", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.dims_gate", "modulename": "bpp.model.egnn", "qualname": "EGNN.dims_gate", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.dims_pos", "modulename": "bpp.model.egnn", "qualname": "EGNN.dims_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.num_pos", "modulename": "bpp.model.egnn", "qualname": "EGNN.num_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.num_encode", "modulename": "bpp.model.egnn", "qualname": "EGNN.num_encode", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.update_pos", "modulename": "bpp.model.egnn", "qualname": "EGNN.update_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.gate_msg", "modulename": "bpp.model.egnn", "qualname": "EGNN.gate_msg", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.norm", "modulename": "bpp.model.egnn", "qualname": "EGNN.norm", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.init", "modulename": "bpp.model.egnn", "qualname": "EGNN.init", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.edge_net", "modulename": "bpp.model.egnn", "qualname": "EGNN.edge_net", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.node_net", "modulename": "bpp.model.egnn", "qualname": "EGNN.node_net", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.EGNN.reset_parameters", "modulename": "bpp.model.egnn", "qualname": "EGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.EGNN.forward", "modulename": "bpp.model.egnn", "qualname": "EGNN.forward", "kind": "function", "doc": "<p>Compute forward pass.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Node features.</li>\n<li><strong>pos:</strong>  Node coordinates.</li>\n<li><strong>edge_index:</strong>  Graph connectivity.</li>\n<li><strong>edge_attr:</strong>  Edge features.</li>\n<li><strong>batch:</strong>  Node to batch mapping.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of updated node features and coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">edge_index</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">edge_attr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.EGNN.message", "modulename": "bpp.model.egnn", "qualname": "EGNN.message", "kind": "function", "doc": "<p>Compute messages.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x_i:</strong>  Source node features.</li>\n<li><strong>x_j:</strong>  Target node features.</li>\n<li><strong>pos_i:</strong>  Source node coordinates.</li>\n<li><strong>pos_j:</strong>  Target node coordinates.</li>\n<li><strong>edge_attr:</strong>  Edge features; between source and target node.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of messages between source and target nodes, and difference\n  between source and target node coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x_i</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">x_j</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos_i</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">pos_j</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">edge_attr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.EGNN.aggregate", "modulename": "bpp.model.egnn", "qualname": "EGNN.aggregate", "kind": "function", "doc": "<p>Aggregate messages.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>messages:</strong>  Tuple of messages and coordinate differences between\nnodes.</li>\n<li><strong>index:</strong>  Indices of elements for applying the aggregation. Either\n<code>index</code> or <code>ptr</code> must be defined.</li>\n<li><strong>ptr:</strong>  Offsets for computing the aggregation based on sorted inputs,\nif provided. Either <code>index</code> or <code>ptr</code> must be defined.</li>\n<li><strong>dim_size:</strong>  Size of output at dimension <code>self.node_dim</code> after\naggregation.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of aggregated messages and aggregated coordinate updates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">messages</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">index</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ptr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">dim_size</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.EGNN.update", "modulename": "bpp.model.egnn", "qualname": "EGNN.update", "kind": "function", "doc": "<p>Update nodes.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>messages:</strong>  Tuple of aggregated messages and coordinate differences.</li>\n<li><strong>x:</strong>  Node features.</li>\n<li><strong>pos:</strong>  Node coordinates.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of updated node features and updated node coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">messages</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.DeepEGNN", "modulename": "bpp.model.egnn", "qualname": "DeepEGNN", "kind": "class", "doc": "<p>Deep E(n) Equivariant Neural Network.</p>\n\n<p>Implementation of an E(n) Equivariant Neural Network with <code>EGNN</code> as\nits layers.</p>\n\n<p>Arguments can be broadcasted to individual layers during initialization. For\nexample, if <code>layers = 4</code> and <code>dims_node = (64, 32)</code>, then <code>dims_node</code> will\nbe used for each of the 4 layers to initialize the hidden and output layer\nof the node network. If on the other hand <code>dims_node = [(64, 32), (128, 64),\n(128, 64), (64, 32)]</code>, then the first and last layer will use <code>(64, 32)</code> and\nthe second and third layer will use <code>(128, 64)</code> to initialize their hidden\nand output layers.</p>\n\n<h6 id=\"example\">Example:</h6>\n\n<blockquote>\n  <p>DeepEGNN instance with 16 input and 64 output features with 2 EGNN\n  layers each having 64 and 128 hidden node features and 32 and 64\n  intermediate output node features.</p>\n  \n  <div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">egnn</span> <span class=\"kn\">import</span> <span class=\"n\">DeepEGNN</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fn</span> <span class=\"o\">=</span> <span class=\"n\">DeepEGNN</span><span class=\"p\">(</span>\n<span class=\"gp\">... </span>    <span class=\"n\">dims_node</span><span class=\"o\">=</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)],</span>\n<span class=\"gp\">... </span>    <span class=\"n\">dims_edge</span><span class=\"o\">=</span><span class=\"p\">[(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)],</span>\n<span class=\"gp\">... </span>    <span class=\"n\">layers</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n<span class=\"gp\">... </span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fn</span>\n<span class=\"go\">DeepEGNN(</span>\n<span class=\"go\">  (layers): ModuleList(</span>\n<span class=\"go\">    (0): ModuleDict(</span>\n<span class=\"go\">      (egnn): EGNN(</span>\n<span class=\"go\">        (aggr_mean): MeanAggregation()</span>\n<span class=\"go\">        (aggr_sum): SumAggregation()</span>\n<span class=\"go\">        (edge_net): Sequential(</span>\n<span class=\"go\">          (0): Linear(in_features=33, out_features=64, bias=True)</span>\n<span class=\"go\">          (1): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">          (2): Linear(in_features=64, out_features=32, bias=True)</span>\n<span class=\"go\">          (3): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">          (4): Linear(in_features=32, out_features=64, bias=True)</span>\n<span class=\"go\">          (5): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">        )</span>\n<span class=\"go\">        (node_net): Sequential(</span>\n<span class=\"go\">          (0): Linear(in_features=80, out_features=64, bias=True)</span>\n<span class=\"go\">          (1): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">          (2): Linear(in_features=64, out_features=32, bias=True)</span>\n<span class=\"go\">        )</span>\n<span class=\"go\">      )</span>\n<span class=\"go\">      (drop): Identity()</span>\n<span class=\"go\">      (norm): ModuleDict(</span>\n<span class=\"go\">        (x): Identity()</span>\n<span class=\"go\">        (pos): Identity()</span>\n<span class=\"go\">      )</span>\n<span class=\"go\">    )</span>\n<span class=\"go\">    (1): ModuleDict(</span>\n<span class=\"go\">      (egnn): EGNN(</span>\n<span class=\"go\">        (aggr_mean): MeanAggregation()</span>\n<span class=\"go\">        (aggr_sum): SumAggregation()</span>\n<span class=\"go\">        (edge_net): Sequential(</span>\n<span class=\"go\">          (0): Linear(in_features=65, out_features=64, bias=True)</span>\n<span class=\"go\">          (1): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">          (2): Linear(in_features=64, out_features=32, bias=True)</span>\n<span class=\"go\">          (3): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">          (4): Linear(in_features=32, out_features=64, bias=True)</span>\n<span class=\"go\">          (5): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">        )</span>\n<span class=\"go\">        (node_net): Sequential(</span>\n<span class=\"go\">          (0): Linear(in_features=96, out_features=128, bias=True)</span>\n<span class=\"go\">          (1): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">          (2): Linear(in_features=128, out_features=64, bias=True)</span>\n<span class=\"go\">        )</span>\n<span class=\"go\">      )</span>\n<span class=\"go\">      (drop): Identity()</span>\n<span class=\"go\">      (norm): ModuleDict(</span>\n<span class=\"go\">        (x): Identity()</span>\n<span class=\"go\">        (pos): Identity()</span>\n<span class=\"go\">      )</span>\n<span class=\"go\">    )</span>\n<span class=\"go\">    (2): ModuleDict(</span>\n<span class=\"go\">      (egnn): EGNN(</span>\n<span class=\"go\">        (aggr_mean): MeanAggregation()</span>\n<span class=\"go\">        (aggr_sum): SumAggregation()</span>\n<span class=\"go\">        (edge_net): Sequential(</span>\n<span class=\"go\">          (0): Linear(in_features=129, out_features=64, bias=True)</span>\n<span class=\"go\">          (1): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">          (2): Linear(in_features=64, out_features=32, bias=True)</span>\n<span class=\"go\">          (3): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">          (4): Linear(in_features=32, out_features=64, bias=True)</span>\n<span class=\"go\">          (5): GELU(approximate=&#39;tanh&#39;)</span>\n<span class=\"go\">        )</span>\n<span class=\"go\">        (node_net): Sequential(</span>\n<span class=\"go\">          (0): Linear(in_features=128, out_features=64, bias=True)</span>\n<span class=\"go\">        )</span>\n<span class=\"go\">      )</span>\n<span class=\"go\">      (drop): Identity()</span>\n<span class=\"go\">      (norm): ModuleDict(</span>\n<span class=\"go\">        (x): Identity()</span>\n<span class=\"go\">        (pos): Identity()</span>\n<span class=\"go\">      )</span>\n<span class=\"go\">    )</span>\n<span class=\"go\">  )</span>\n<span class=\"go\">)</span>\n</code></pre>\n  </div>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.egnn.DeepEGNN.__init__", "modulename": "bpp.model.egnn", "qualname": "DeepEGNN.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>dims_node:</strong>  Dimensions for the node networks. This can be a sequence\nof integers with <code>dims_node[0]</code> describing the number of input\nfeatures and <code>dims_node[-1]</code> describing the number output\nfeatures for the node networks in all layers. Note that the\nnumber of input features is only valid for the first layer; in\nall subsequent layers the number of input features is inferred\nfrom the number of output features of the previous layer.\nAlternatively, <code>dims_node</code> can also be a sequence of sequences\nof integers, describing the aforementioned properties for each\nlayer individually. In this case, <code>dims_node[0][0]</code> is the\nnumber of input features for the first layer, but for all\nsubsequent layers the first value represents the dimension of\nthe first hidden layer of the node networks, since the number of\ninput features is inferred from the previous number of output\nfeatures of the previous layer; e.g., <code>dims_node[1][0]</code> is the\ndimension of the first hidden layer in the node network of the\nsecond layer in this network.</li>\n<li><strong>dims_edge:</strong>  Dimensions for the edge networks. Follows the same\nbroadcasting scheme as <code>dims_node</code>.</li>\n<li><strong>dims_gate:</strong>  Dimensions for the message gating network. Follows the\nsame broadcasting scheme as <code>dims_node</code>. If empty, message\ngating is disabled.</li>\n<li><strong>dims_pos:</strong>  Dimensions for the coordinate update network. Follows the\nsame broadcasting scheme as <code>dims_node</code>. If empty, coordinate\nupdate is disabled.</li>\n<li><strong>layers:</strong>  Number of <code>EGNN</code> layers.</li>\n<li><strong>num_pos:</strong>  Number of node positions.</li>\n<li><strong>dim_pos:</strong>  Number of coordinate dimensions.</li>\n<li><strong>num_encode:</strong>  Number of fourier-encoded features.</li>\n<li><strong>pos_scale:</strong>  Initial scaler for coordinate updates. If pos_scale is\n0, the penultimate layer of a coordinate update network will\nuse a linear activation and omit the scaling factor.</li>\n<li><strong>norm:</strong>  Whether to normalize a given layer and whether to use\nnormalization after that given layer. If a single boolean or a\nlist of single booleans, then normalization will be applied\nwithin and after the corresponding layers according to the\nboolean value. If a tuple of booleans or a list of tuples of\nbooleans, then the first boolean will determine whether to use\nnormalization after a layer and the second will determine\nwhether to use normalization within that layer.</li>\n<li><strong>clamp:</strong>  Threshold for clamping coordinate updates (between <code>-clamp</code>\nand <code>clamp</code>). Unclamped if 0.</li>\n<li><strong>dropout:</strong>  Dropout probabilities for in-between layers and within\nlayers. Values will be broadcasted to all layers, if only two\nprobabilities are given, or to all layers and in-between and\nwithin layers, if only one probability is given. Dropout is\nomitted if 0.</li>\n<li><strong>residual:</strong>  Whether a layer is a residual layer. If <code>residual</code> is a\nsingle value, then layers will only be residual layers if their\nnumber of input and output features matches. Coordinates are not\nupdated through residual connections, independent of this\ntoggle.</li>\n<li><strong>activation:</strong>  Activation function that is used for the <code>EGNN</code>\nlayers.</li>\n<li><strong>init:</strong>  Initializer that is used for network layers. First argument is\nthe module that should be initialized, the second is the\nnon-linearity, in case of a linear module, that should be used.\nThe default non-linearity should adhere to whatever is used for\n<code>activation</code>. See <code>parameter_init()</code>.</li>\n<li><strong>norm_cls:</strong>  Class instance of normalization module.</li>\n<li><strong>dropout_cls:</strong>  Class instance of dropout module.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">[()]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">[()]</span>,</span><span class=\"param\">\t<span class=\"n\">layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">dim_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">residual</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]],</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]]],</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: Union[Sequence[type[torch.nn.modules.module.Module]], type[torch.nn.modules.module.Module]] = &lt;class &#x27;torch.nn.modules.batchnorm.BatchNorm1d&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: Union[Sequence[type[torch.nn.modules.module.Module]], type[torch.nn.modules.module.Module]] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;</span>)</span>"}, {"fullname": "bpp.model.egnn.DeepEGNN.residual", "modulename": "bpp.model.egnn", "qualname": "DeepEGNN.residual", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.DeepEGNN.init", "modulename": "bpp.model.egnn", "qualname": "DeepEGNN.init", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.DeepEGNN.layers", "modulename": "bpp.model.egnn", "qualname": "DeepEGNN.layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.DeepEGNN.reset_parameters", "modulename": "bpp.model.egnn", "qualname": "DeepEGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.DeepEGNN.forward", "modulename": "bpp.model.egnn", "qualname": "DeepEGNN.forward", "kind": "function", "doc": "<p>Compute forward pass.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Node features.</li>\n<li><strong>pos:</strong>  Node coordinates.</li>\n<li><strong>edge_index:</strong>  Graph connectivity.</li>\n<li><strong>edge_attr:</strong>  Edge features.</li>\n<li><strong>batch:</strong>  Node to batch mapping.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of updated node features and updated coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">edge_index</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">edge_attr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit", "modulename": "bpp.model.egnn.implicit", "kind": "module", "doc": "<p>Module containing implementations of Deep Equilibrium E(n) Equivariant Graph\nNeural Networks.</p>\n\n<h6 id=\"references\">References:</h6>\n\n<blockquote>\n  <p>[^1]: Bai, S., Kolter, J. Z., &amp; Koltun, V. (2019). Deep Equilibrium Models.</p>\n</blockquote>\n"}, {"fullname": "bpp.model.egnn.implicit.DEFAULT_DEQ_ARGS", "modulename": "bpp.model.egnn.implicit", "qualname": "DEFAULT_DEQ_ARGS", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;core&#x27;: &#x27;sliced&#x27;, &#x27;ift&#x27;: True, &#x27;hook_ift&#x27;: False, &#x27;f_solver&#x27;: &#x27;anderson&#x27;, &#x27;f_max_iter&#x27;: 75, &#x27;f_tol&#x27;: 0.001, &#x27;b_solver&#x27;: &#x27;anderson&#x27;, &#x27;b_max_iter&#x27;: 100, &#x27;b_tol&#x27;: 1e-06}"}, {"fullname": "bpp.model.egnn.implicit.DEFAULT_SOLVER_ARGS", "modulename": "bpp.model.egnn.implicit", "qualname": "DEFAULT_SOLVER_ARGS", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;tau&#x27;: 1.0, &#x27;m&#x27;: 6, &#x27;lam&#x27;: 0.0001}"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN", "kind": "class", "doc": "<p></p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.__init__", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">dim_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">jacobi_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">residual_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.normalization.LayerNorm&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">deq_args</span><span class=\"p\">:</span> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">&#39;core&#39;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;sliced&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;ift&#39;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s1\">&#39;hook_ift&#39;</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"s1\">&#39;f_solver&#39;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;anderson&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;f_max_iter&#39;</span><span class=\"p\">:</span> <span class=\"mi\">75</span><span class=\"p\">,</span> <span class=\"s1\">&#39;f_tol&#39;</span><span class=\"p\">:</span> <span class=\"mf\">0.001</span><span class=\"p\">,</span> <span class=\"s1\">&#39;b_solver&#39;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;anderson&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;b_max_iter&#39;</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"s1\">&#39;b_tol&#39;</span><span class=\"p\">:</span> <span class=\"mf\">1e-06</span><span class=\"p\">}</span>,</span><span class=\"param\">\t<span class=\"n\">solver_args</span><span class=\"p\">:</span> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">&#39;tau&#39;</span><span class=\"p\">:</span> <span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"s1\">&#39;m&#39;</span><span class=\"p\">:</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"s1\">&#39;lam&#39;</span><span class=\"p\">:</span> <span class=\"mf\">0.0001</span><span class=\"p\">}</span>,</span><span class=\"param\">\t<span class=\"n\">unrecorded</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.update_pos", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.update_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.jacobi_penalty", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.jacobi_penalty", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.residual_penalty", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.residual_penalty", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.activation", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.activation", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.init", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.init", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.deq", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.deq", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.deq_args", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.deq_args", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.solver_args", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.solver_args", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.egnn_1", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.egnn_1", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.egnn_2", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.egnn_2", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.inject", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.inject", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.reset_parameters", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit.ImplicitEGNN.forward", "modulename": "bpp.model.egnn.implicit", "qualname": "ImplicitEGNN.forward", "kind": "function", "doc": "<p>Compute forward pass.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Node features.</li>\n<li><strong>pos:</strong>  Node coordinates.</li>\n<li><strong>edge_index:</strong>  Graph connectivity.</li>\n<li><strong>edge_attr:</strong>  Edge features.</li>\n<li><strong>batch:</strong>  Node to batch mapping.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of updated node features and updated coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">edge_index</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">edge_attr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit_backup_1", "modulename": "bpp.model.egnn.implicit_backup_1", "kind": "module", "doc": "<p>Module containing implementations of Deep Equilibrium E(n) Equivariant Graph\nNeural Networks.</p>\n\n<h6 id=\"references\">References:</h6>\n\n<blockquote>\n  <p>[^1]: Bai, S., Kolter, J. Z., &amp; Koltun, V. (2019). Deep Equilibrium Models.</p>\n</blockquote>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_1.Size", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "Size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": TypeAlias", "default_value": "tuple[int, ...]"}, {"fullname": "bpp.model.egnn.implicit_backup_1.sizeof", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "sizeof", "kind": "function", "doc": "<p>Returns sizes of tensors.</p>\n\n<p><strong>Note</strong>: first dimension is ignored.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>tensors:</strong>  List of tensors.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>List of sizes of tensors.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tensors</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit_backup_1.pack", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "pack", "kind": "function", "doc": "<p>Pack list of tensors into vector.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>tensors:</strong>  List of tensors.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Vector.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tensors</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit_backup_1.unpack", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "unpack", "kind": "function", "doc": "<p>Unpack vector into list of tensors.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>vec:</strong>  Vector.</li>\n<li><strong>sizes:</strong>  List of sizes for tensors.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>List of tensors.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">vec</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">sizes</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">]]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN", "kind": "class", "doc": "<p></p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.__init__", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">dim_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">update</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">gate</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">fw_solver</span><span class=\"p\">:</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">bw_solver</span><span class=\"p\">:</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.egnn", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.egnn", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.norm_x_0", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.norm_x_0", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.norm_x_1", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.norm_x_1", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.norm_pos", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.norm_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.fw_solver", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.fw_solver", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.bw_solver", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.bw_solver", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.hook", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.hook", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.reset_parameters", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit_backup_1.DeepImplicitEGNN.forward", "modulename": "bpp.model.egnn.implicit_backup_1", "qualname": "DeepImplicitEGNN.forward", "kind": "function", "doc": "<p>Compute forward pass.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Node features.</li>\n<li><strong>pos:</strong>  Node coordinates.</li>\n<li><strong>edge_index:</strong>  Graph connectivity.</li>\n<li><strong>edge_attr:</strong>  Edge features.</li>\n<li><strong>batch:</strong>  Node to batch mapping.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of updated node features and updated coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">edge_index</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">edge_attr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit_backup_2", "modulename": "bpp.model.egnn.implicit_backup_2", "kind": "module", "doc": "<p>Module containing implementations of Deep Equilibrium E(n) Equivariant Graph\nNeural Networks.</p>\n\n<h6 id=\"references\">References:</h6>\n\n<blockquote>\n  <p>[^1]: Bai, S., Kolter, J. Z., &amp; Koltun, V. (2019). Deep Equilibrium Models.</p>\n</blockquote>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.Size", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "Size", "kind": "variable", "doc": "<p></p>\n", "annotation": ": TypeAlias", "default_value": "tuple[int, ...]"}, {"fullname": "bpp.model.egnn.implicit_backup_2.parameter_init", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "parameter_init", "kind": "function", "doc": "<p>Initialize module parameters. Uses kaiming initialization for linear\nmodules and sets parameters of other modules accordingly.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>module:</strong>  Module that parameters should be initialized.</li>\n<li><strong>nonlinearity:</strong>  Nonlinearity that should be assumed for linear modules.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">module</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">nonlinearity</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;relu&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN", "kind": "class", "doc": "<p></p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.__init__", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">dim_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">jacobi_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">fixed_point_penalty</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">residual</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.normalization.LayerNorm&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">deq</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torchdeq</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">DEQBase</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.dims_node", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.dims_node", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.dims_edge", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.dims_edge", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.num_pos", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.num_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.dim_pos", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.dim_pos", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.num_encode", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.num_encode", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.norm", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.norm", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.clamp", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.clamp", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.dropout", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.dropout", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.jacobi_penalty", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.jacobi_penalty", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.fixed_point_penalty", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.fixed_point_penalty", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.residual", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.residual", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.activation", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.activation", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.init", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.init", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.deq", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.deq", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.node_mix_in", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.node_mix_in", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.channels", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.channels", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.inject", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.inject", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.norm2", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.norm2", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.norm3", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.norm3", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.norm4", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.norm4", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.pos_norm_1", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.pos_norm_1", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.pos_norm_2", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.pos_norm_2", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.reset_parameters", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.implicit_backup_2.ImplicitEGNN.forward", "modulename": "bpp.model.egnn.implicit_backup_2", "qualname": "ImplicitEGNN.forward", "kind": "function", "doc": "<p>Compute forward pass.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Node features.</li>\n<li><strong>pos:</strong>  Node coordinates.</li>\n<li><strong>edge_index:</strong>  Graph connectivity.</li>\n<li><strong>edge_attr:</strong>  Edge features.</li>\n<li><strong>batch:</strong>  Node to batch mapping.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of updated node features and updated coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">edge_index</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">edge_attr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.reversible", "modulename": "bpp.model.egnn.reversible", "kind": "module", "doc": "<p>Module containing implementation of reversible E(n) Equivariant Graph Neural\nNetworks.</p>\n\n<p>These variants are primarily used for saving memory by not storing any\nintermediate values and recomputing the inputs and required intermediate values\nin an auto-regressive scheme from the outputs of a given layer during\nback-propagation.</p>\n\n<p><strong>Note</strong>: PyTorch does not provide a feasible solution on how to pass the\noutputs to the backwards function without storing them as intermediate results,\nmeaning that we would need to free and reallocate the memory of a given value\nmanually. However, this often causes memory leaks, invalid accesses' or only\ncopies of a value to be freed. If we however manage to make an architecture\nwork, we often end up with numerical issues; e.g., normalization modules. This\nis why, by default, the outputs of each layer will be stored as intermediate\nvalues during the forward pass.</p>\n\n<h6 id=\"references\">References:</h6>\n\n<blockquote>\n  <p>[^1]: Li, G., M\u00fcller, M., Ghanem, B., &amp; Koltun, V. (2022). Training Graph\n         Neural Networks with 1000 Layers.\n  [^2]: Rezende, D. J., &amp; Mohamed, S. (2016). Variational Inference with\n         Normalizing Flows.</p>\n</blockquote>\n"}, {"fullname": "bpp.model.egnn.reversible.ReversibleEGNN", "modulename": "bpp.model.egnn.reversible", "qualname": "ReversibleEGNN", "kind": "class", "doc": "<p>Reversible E(n) Equivariant Graph Neural Network.</p>\n\n<p>Implementation of an E(n) Equivariant Graph Neural Network with reversible\nlayers to omit storing any intermediate values during the forward pass when\ncomputing the differentials. Inputs of each layer are computed in reverse\nfrom the outputs to compute the differentials of a given layer.</p>\n\n<p>Please refer to <code>bpp.model.egnn.EGNN</code> for further details on how to\nuse this module.</p>\n", "bases": "bpp.model._reversible.ReversibleModule"}, {"fullname": "bpp.model.egnn.reversible.ReversibleEGNN.__init__", "modulename": "bpp.model.egnn.reversible", "qualname": "ReversibleEGNN.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>dims_node:</strong>  Dimensions for the node network of a block:\n<code>dims_node[0]</code> is the number of input features and\n<code>dims_node[-1]</code> is the number of output features. At least 2\ndimensions are required. All remaining dimensions are used for\nthe hidden-layers of the network.</li>\n<li><strong>dims_edge:</strong>  Dimensions for the edge network of a block:\n<code>dims_edge[0]</code> is the number of edge features (0 if graphs have\nno edge features), <code>dims_edge[-2]</code> is the number of message\nfeatures and <code>dims_edge[-1]</code> is the number of hidden-layer\nfeatures for the coordinate update and message gating networks\n(ignored if neither <code>update</code> nor <code>gate</code> are enabled). All\nremaining dimensions are used for the hidden-layers of the edge\nnetwork that computes the messages.</li>\n<li><strong>blocks:</strong>  Number of blocks in the auto-regressive reversible layer;\ni.e., individual instances of <code>bpp.model.egnn.EGNN</code>. At\nleast 2 are necessary.</li>\n<li><strong>num_pos:</strong>  Number of node positions. Each node can be assigned to one\nposition, but can also be assigned to multiple positions.</li>\n<li><strong>num_encode:</strong>  Number of fourier-encoded features that are computed\nfrom the distances between node coordinates. If <code>num_encode</code> is\neven, only the fourier-encoded features will be used. If odd,\nthe original distances will also be used alongside the\nfourier-encoded features.  Default is 1, which means that only\nthe original distances are used, without any fourier features.</li>\n<li><strong>update:</strong>  Whether to update node coordinates.</li>\n<li><strong>gate:</strong>  Whether to gate messages before aggregation.</li>\n<li><strong>norm:</strong>  Whether to use layer and message normalization while computing\nand aggregating messages.</li>\n<li><strong>clamp:</strong>  Threshold for clamping coordinate updates (between <code>-clamp</code>\nand <code>clamp</code>). Unclamped if 0.</li>\n<li><strong>dropout:</strong>  Dropout probabilities for inputs and within network layers\nof a block. If only one probability is given, then this will be\nused for the inputs and in-between layers. Dropout is omitted if\n0.</li>\n<li><strong>activation:</strong>  Activation function that is used in-between network\nlayers.</li>\n<li><strong>init:</strong>  Initializer that is used for network layers. First argument is\nthe module that should be initialized, the second is the\nnon-linearity, in case of a linear module, that should be used.\nThe default non-linearity should adhere to whatever is used for\n<code>activation</code>. See <code>bpp.model.egnn.parameter_init()</code>.</li>\n<li><strong>disable:</strong>  Whether to disable reversible computations and use\nconventional back-propagation method. Used primarily for\ndebugging.</li>\n<li><strong>free_inputs:</strong>  Whether to free inputs. Disabled by default due to\nnumerical issues.</li>\n<li><strong>free_outputs:</strong>  Whether to free outputs. Disabled by default due to\nnumerical issues.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">blocks</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">dim_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.batchnorm.BatchNorm1d&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">disable</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">free_inputs</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">free_outputs</span><span class=\"o\">=</span><span class=\"kc\">False</span></span>)</span>"}, {"fullname": "bpp.model.egnn.reversible.ReversibleEGNN.init", "modulename": "bpp.model.egnn.reversible", "qualname": "ReversibleEGNN.init", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.reversible.ReversibleEGNN.deterministic_contexts", "modulename": "bpp.model.egnn.reversible", "qualname": "ReversibleEGNN.deterministic_contexts", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.reversible.ReversibleEGNN.blocks", "modulename": "bpp.model.egnn.reversible", "qualname": "ReversibleEGNN.blocks", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.reversible.ReversibleEGNN.reset_parameters", "modulename": "bpp.model.egnn.reversible", "qualname": "ReversibleEGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.reversible.SimplifiedReversibleEGNN", "modulename": "bpp.model.egnn.reversible", "qualname": "SimplifiedReversibleEGNN", "kind": "class", "doc": "<p>Simplified variant of the Reversible E(n) Equivariant Graph Neural\nNetwork.</p>\n\n<p>This variant uses an auto-regressive update scheme that is more in line\nwith [2]_.</p>\n\n<p>Please refer to <code>bpp.model.egnn.EGNN</code> for further details on how to\nuse this module.</p>\n", "bases": "ReversibleEGNN"}, {"fullname": "bpp.model.egnn.reversible.SimplifiedReversibleEGNN.__init__", "modulename": "bpp.model.egnn.reversible", "qualname": "SimplifiedReversibleEGNN.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>dims_node:</strong>  Dimensions for the node network of a block:\n<code>dims_node[0]</code> is the number of input features and\n<code>dims_node[-1]</code> is the number of output features. At least 2\ndimensions are required. All remaining dimensions are used for\nthe hidden-layers of the network.</li>\n<li><strong>dims_edge:</strong>  Dimensions for the edge network of a block:\n<code>dims_edge[0]</code> is the number of edge features (0 if graphs have\nno edge features), <code>dims_edge[-1]</code> is the number of message\nfeatures.  All remaining dimensions are used for the\nhidden-layers of the edge network that computes the messages.</li>\n<li><strong>blocks:</strong>  Number of blocks in the auto-regressive reversible layer;\ni.e., individual instances of <code>bpp.model.egnn.EGNN</code>. At\nleast one block is required.</li>\n<li><strong>dims_gate:</strong>  Dimensions for the message gating network. If empty,\nno message gating network will be created and message gating\nwill be disabled.</li>\n<li><strong>dims_pos:</strong>  Dimensions for the coordinate update network. If empty,\nno coordinate update network will be created and coordinate\nupdates will be disabled.</li>\n<li><strong>num_pos:</strong>  Number of node positions. Each node can be assigned to one\nposition, but can also be assigned to multiple positions.</li>\n<li><strong>num_encode:</strong>  Number of fourier-encoded features that are computed\nfrom the distances between node coordinates. If <code>num_encode</code> is\neven, only the fourier-encoded features will be used. If odd,\nthe original distances will also be used alongside the\nfourier-encoded features.  Default is 1, which means that only\nthe original distances are used, without any fourier features.</li>\n<li><strong>pos_scale:</strong>  Initial scaler for coordinate updates. If pos_scale is\n0, the penultimate layer of a coordinate update network will\nuse a linear activation and omit the scaling factor.</li>\n<li><strong>norm:</strong>  Whether to use normalization within a block and whether to use\nnormalization after a block. If only one value is given, then\nnormalization within and after a block will be applied\naccordingly. If two values are given, then the first determines\nwhether to apply normalization after a block and the second\nwhether to apply normalization within a block.</li>\n<li><strong>clamp:</strong>  Threshold for clamping coordinate updates (between <code>-clamp</code>\nand <code>clamp</code>). Unclamped if 0.</li>\n<li><strong>dropout:</strong>  Dropout probabilities for inputs and within network layers\nof a block. If only one probability is given, then this will be\nused for the inputs and in-between layers. Dropout is omitted if\n0.</li>\n<li><strong>activation:</strong>  Activation function that is used in-between network\nlayers.</li>\n<li><strong>init:</strong>  Initializer that is used for network layers. First argument is\nthe module that should be initialized, the second is the\nnon-linearity, in case of a linear module, that should be used.\nThe default non-linearity should adhere to whatever is used for\n<code>activation</code>. See <code>bpp.model.egnn.parameter_init()</code>.</li>\n<li><strong>norm_cls:</strong>  Class instance of normalization module.</li>\n<li><strong>dropout_cls:</strong>  Class instance of dropout module.</li>\n<li><strong>disable:</strong>  Whether to disable reversible computations and use\nconventional back-propagation method. Used primarily for\ndebugging.</li>\n<li><strong>free_inputs:</strong>  Whether to free inputs. Disabled by default due to\nnumerical issues.</li>\n<li><strong>free_outputs:</strong>  Whether to free outputs. Disabled by default due to\nnumerical issues.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">blocks</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">dim_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.batchnorm.BatchNorm1d&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">disable</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">free_inputs</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">free_outputs</span><span class=\"o\">=</span><span class=\"kc\">False</span></span>)</span>"}, {"fullname": "bpp.model.egnn.reversible.DeepReversibleEGNN", "modulename": "bpp.model.egnn.reversible", "qualname": "DeepReversibleEGNN", "kind": "class", "doc": "<p>Deep Reversible E(n) Equivariant Graph Neural Network.</p>\n\n<p>Implementation of a Deep Reversible E(n) Equivariant Graph Neural Network\nthat utilizes reversible layers for saving memory during back-propagation.</p>\n\n<p>Please refer to <code>bpp.model.egnn.DeepEGNN</code> for further details on how\nto use this module.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.egnn.reversible.DeepReversibleEGNN.__init__", "modulename": "bpp.model.egnn.reversible", "qualname": "DeepReversibleEGNN.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>dims_node:</strong>  Dimensions for the node networks. This can be a sequence\nof integers with <code>dims_node[0]</code> describing the number of input\nfeatures and all remaining dimensions describing the number of\nfeatures in the hidden layers. Note that the number of output\nfeatures will always be the same as the number of input features\nfor this variant of an EGNN model. Alternatively, <code>dims_node</code>\ncan also be a sequence of sequences of integers, describing the\naforementioned properties for each layer individually. In this\ncase, only the number of input features in the definition of the\nfirst layer must be provided and for all other layers the number\nof input features is omitted, since it is derived from the\nthe previous layer.</li>\n<li><strong>dims_edge:</strong>  Dimensions for the edge networks. Follows the same\nbroadcasting scheme as <code>dims_node</code>.</li>\n<li><strong>dims_gate:</strong>  Dimensions for the message gating network. Follows the\nsame broadcasting scheme as <code>dims_node</code>. If empty, message\ngating is disabled.</li>\n<li><strong>dims_pos:</strong>  Dimensions for the coordinate update network. Follows the\nsame broadcasting scheme as <code>dims_node</code>. If empty, coordinate\nupdate is disabled.</li>\n<li><strong>blocks:</strong>  Number of blocks in the auto-regressive reversible layer;\ni.e., individual instances of <code>bpp.model.egnn.EGNN</code>. At\nleast two blocks are required and the number of node input\nfeatures must be divisible by the number of blocks.</li>\n<li><strong>layers:</strong>  Number of layers.</li>\n<li><strong>num_pos:</strong>  Number of node positions.</li>\n<li><strong>dim_pos:</strong>  Number of coordinate dimensions.</li>\n<li><strong>num_encode:</strong>  Number of fourier-encoded features.</li>\n<li><strong>pos_scale:</strong>  Initial scaler for coordinate updates. If <code>pos_scale</code> is\n0, the penultimate layer of a coordinate update network will\nuse a linear activation and omit the scaling factor.</li>\n<li><strong>norm:</strong>  Whether to use normalization within a block and whether to use\nnormalization after a block. If a single boolean or a list of\nsingle booleans, then normalization will be applied within and\nafter the corresponding blocks of a layer according to the\nboolean value. If a tuple of booleans or a list of tuples of\nbooleans, then the first boolean will determine whether to use\nnormalization after a block and the second will determine\nwhether to use normalization within that block.</li>\n<li><strong>clamp:</strong>  Threshold for clamping coordinate updates (between <code>-clamp</code>\nand <code>clamp</code>). Unclamped if 0.</li>\n<li><strong>dropout:</strong>  Dropout probabilities for in-between layers and within\nlayers. Values will be broadcasted to all layers, if only two\nprobabilities are given, or to all layers and in-between and\nwithin layers, if only one probability is given. Dropout is\nomitted if 0.</li>\n<li><strong>activation:</strong>  Activation function that is used for the <code>EGNN</code>\nlayers.</li>\n<li><strong>init:</strong>  Initializer that is used for network layers. First argument is\nthe module that should be initialized, the second is the\nnon-linearity, in case of a linear module, that should be used.\nThe default non-linearity should adhere to whatever is used for\n<code>activation</code>. See <code>parameter_init()</code>.</li>\n<li><strong>layer_cls:</strong>  Class instance of the reversible layer.</li>\n<li><strong>norm_cls:</strong>  Class instance of normalization module.</li>\n<li><strong>dropout_cls:</strong>  Class instance of dropout module.</li>\n<li><strong>disable:</strong>  Whether to disable reversible computations and use\nconventional back-propagation method. Used primarily for\ndebugging.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">blocks</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">dim_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]],</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]],</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]]],</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tlayer_cls: Union[Sequence[torch.nn.modules.module.Module], torch.nn.modules.module.Module] = &lt;class &#x27;bpp.model.egnn.reversible.ReversibleEGNN&#x27;&gt;,</span><span class=\"param\">\tnorm_cls: Union[Sequence[type[torch.nn.modules.module.Module]], type[torch.nn.modules.module.Module]] = &lt;class &#x27;torch.nn.modules.batchnorm.BatchNorm1d&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: Union[Sequence[type[torch.nn.modules.module.Module]], type[torch.nn.modules.module.Module]] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">disable</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "bpp.model.egnn.reversible.DeepReversibleEGNN.layers", "modulename": "bpp.model.egnn.reversible", "qualname": "DeepReversibleEGNN.layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.reversible.DeepReversibleEGNN.reset_parameters", "modulename": "bpp.model.egnn.reversible", "qualname": "DeepReversibleEGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.reversible.DeepReversibleEGNN.forward", "modulename": "bpp.model.egnn.reversible", "qualname": "DeepReversibleEGNN.forward", "kind": "function", "doc": "<p>Compute forward pass.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Node features.</li>\n<li><strong>pos:</strong>  Node coordinates.</li>\n<li><strong>edge_index:</strong>  Graph connectivity.</li>\n<li><strong>edge_attr:</strong>  Edge features.</li>\n<li><strong>batch:</strong>  Node to batch mapping.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of updated node features and updated coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">edge_index</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">edge_attr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.unrecorded", "modulename": "bpp.model.egnn.unrecorded", "kind": "module", "doc": "<p>Module containing implementations of unrecorded E(n) Equivariant Graph \nNeural Networks.</p>\n\n<p>These variants are primarily used for saving memory by storing only the inputs\nof each layer and recomputing the intermediate values and outputs during\nback-propagation.</p>\n"}, {"fullname": "bpp.model.egnn.unrecorded.UnrecordedEGNN", "modulename": "bpp.model.egnn.unrecorded", "qualname": "UnrecordedEGNN", "kind": "class", "doc": "<p>Unrecorded E(n) Equivariant Graph Neural Network.</p>\n\n<p>Implementation of an E(n) Equivariant Graph Neural Network that only stores\nthe inputs when computing the forward pass during differentiation and that\nrecomputes all intermediate values and the outputs during the backwards\npass to save memory.</p>\n\n<p>Please refer to <code>bpp.model.egnn.EGNN</code> for further details on how to\nuse this module.</p>\n", "bases": "bpp.model._unrecorded.UnrecordedModule"}, {"fullname": "bpp.model.egnn.unrecorded.UnrecordedEGNN.__init__", "modulename": "bpp.model.egnn.unrecorded", "qualname": "UnrecordedEGNN.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>dims_node:</strong>  Dimensions for the node network: <code>dims_node[0]</code> is the\nnumber of input features and <code>dims_node[-1]</code> is the number of\noutput features, <code>dims_node[1]</code> is the number of input-channel\nfeatures and <code>dims_node[-2]</code> is the number of output-channel\nfeatures. At least 4 dimensions are required. All\nremaining dimensions are used for the hidden-layers of the\nnetwork.</li>\n<li><strong>dims_edge:</strong>  Dimensions for the edge network: <code>dims_edge[0]</code> is the\nnumber of edge features (0 if graphs have no edge features),\n<code>dims_edge[-1]</code> is the number of message features.  All\nremaining dimensions are used for the hidden-layers of the edge\nnetwork that computes the messages.</li>\n<li><strong>dims_gate:</strong>  Dimensions for the message gating network. If empty,\nno message gating network will be created and message gating\nwill be disabled.</li>\n<li><strong>dims_pos:</strong>  Dimensions for the coordinate update network. If empty,\nno coordinate update network will be created and coordinate\nupdates will be disabled.</li>\n<li><strong>channels:</strong>  Number of channels; i.e., individual instances of\n<code>bpp.model.egnn.EGNN</code>. Linear mixing layers are used to\ndistribute and recombine features amongst different channels.</li>\n<li><strong>num_pos:</strong>  Number of node positions. Each node can be assigned to one\nposition, but can also be assigned to multiple positions.</li>\n<li><strong>num_encode:</strong>  Number of fourier-encoded features that are computed\nfrom the distances between node coordinates. If <code>num_encode</code> is\neven, only the fourier-encoded features will be used. If odd,\nthe original distances will also be used alongside the\nfourier-encoded features.  Default is 1, which means that only\nthe original distances are used, without any fourier features.</li>\n<li><strong>pos_scale:</strong>  Initial scaler for coordinate updates. If pos_scale is\n0, the penultimate layer of a coordinate update network will\nuse a linear activation and omit the scaling factor.</li>\n<li><strong>norm:</strong>  Whether to use layer and message normalization while computing\nand aggregating messages.</li>\n<li><strong>clamp:</strong>  Threshold for clamping coordinate updates (between <code>-clamp</code>\nand <code>clamp</code>). Unclamped if 0.</li>\n<li><strong>dropout:</strong>  Dropout probability in-between network layers. No dropout\nif 0.</li>\n<li><strong>activation:</strong>  Activation function that is used in-between network\nlayers.</li>\n<li><strong>init:</strong>  Initializer that is used for network layers. First argument is\nthe module that should be initialized, the second is the\nnon-linearity, in case of a linear module, that should be used.\nThe default non-linearity should adhere to whatever is used for\n<code>activation</code>. See <code>bpp.model.egnn.parameter_init()</code>.</li>\n<li><strong>norm_cls:</strong>  Class instance of normalization module.</li>\n<li><strong>dropout_cls:</strong>  Class instance of dropout module.</li>\n<li><strong>disable:</strong>  Whether to disable layer-wise recomputation and store\nintermediate values for the back-propagation method. Used \nprimarily for debugging.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">channels</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.batchnorm.BatchNorm1d&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: type[torch.nn.modules.module.Module] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">disable</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "bpp.model.egnn.unrecorded.UnrecordedEGNN.mix_in", "modulename": "bpp.model.egnn.unrecorded", "qualname": "UnrecordedEGNN.mix_in", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.unrecorded.UnrecordedEGNN.mix_out", "modulename": "bpp.model.egnn.unrecorded", "qualname": "UnrecordedEGNN.mix_out", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.unrecorded.UnrecordedEGNN.channels", "modulename": "bpp.model.egnn.unrecorded", "qualname": "UnrecordedEGNN.channels", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.unrecorded.UnrecordedEGNN.reset_parameters", "modulename": "bpp.model.egnn.unrecorded", "qualname": "UnrecordedEGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.unrecorded.DeepUnrecordedEGNN", "modulename": "bpp.model.egnn.unrecorded", "qualname": "DeepUnrecordedEGNN", "kind": "class", "doc": "<p>Deep Unrecorded E(n) Equivariant Neural Network.</p>\n\n<p>Implementation of an E(n) Equivariant Neural Network that utilizes\n<code>UnrecordedEGNN</code> modules as it's layers to save memory during\ndifferentiation.</p>\n\n<p>Please refer to <code>bpp.model.egnn.DeepEGNN</code> for further detail on how\nto use this module.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bpp.model.egnn.unrecorded.DeepUnrecordedEGNN.__init__", "modulename": "bpp.model.egnn.unrecorded", "qualname": "DeepUnrecordedEGNN.__init__", "kind": "function", "doc": "<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>dims_node:</strong>  Dimensions for the node networks. This can be a sequence\nof integers with <code>dims_node[0]</code> describing the number of input\nfeatures and <code>dims_node[-1]</code> describing the number output\nfeatures for the node networks in all layers. Note that the\nnumber of input features is only valid for the first layer and\nthat in all subsequent layers the number of input features will\nbe the same as the number of output features of the previous\nlayer. Alternatively, <code>dims_node</code> can also be a sequence of\nsequences of integers, describing the aforementioned properties\nfor each layer individually. In this case, <code>dims_node[0][0]</code> is\nthe number of input features for the first layer, but for all\nsubsequent layers the first value represents the dimension of\nthe first hidden layer of the node networks, since the number of\ninput features will be derived from the previous number of\noutput features of the previous layer; e.g., <code>dims_node[1][0]</code>\nis the dimension of the first hidden layer in the node network\nof the second layer in this network. Also note that the\ndimensions must adhere to the specification in\n<code>UnrecordedEGNN</code>, such that they must also specify the\nnumber of channel features.</li>\n<li><strong>dims_edge:</strong>  Dimensions for the edge networks. Follows the same\nbroadcasting scheme as <code>dims_node</code>.</li>\n<li><strong>dims_gate:</strong>  Dimensions for the message gating network. Follows the\nsame broadcasting scheme as <code>dims_node</code>. If empty, message\ngating is disabled.</li>\n<li><strong>dims_pos:</strong>  Dimensions for the coordinate update network. Follows the\nsame broadcasting scheme as <code>dims_node</code>. If empty, coordinate\nupdate is disabled.</li>\n<li><strong>channels:</strong>  Number of channels within each <code>UnrecordedEGNN</code>\nlayer.</li>\n<li><strong>layers:</strong>  Number of <code>UnrecordedEGNN</code> layers.</li>\n<li><strong>num_pos:</strong>  Number of node positions.</li>\n<li><strong>dim_pos:</strong>  Number of coordinate dimensions.</li>\n<li><strong>num_encode:</strong>  Number of fourier-encoded features.</li>\n<li><strong>pos_scale:</strong>  Initial scaler for coordinate updates. If pos_scale is\n0, the penultimate layer of a coordinate update network will\nuse a linear activation and omit the scaling factor.</li>\n<li><strong>norm:</strong>  Whether to normalize a given layer and whether to use\nnormalization after that given layer. If a single boolean or a\nlist of single booleans, then normalization will be applied\nwithin and after the corresponding layers according to the\nboolean value. If a tuple of booleans or a list of tuples of\nbooleans, then the first boolean will determine whether to use\nnormalization after a layer and the second will determine\nwhether to use normalization within that layer.</li>\n<li><strong>clamp:</strong>  Threshold for clamping coordinate updates (between <code>-clamp</code>\nand <code>clamp</code>). Unclamped if 0.</li>\n<li><strong>dropout:</strong>  Dropout probabilities for in-between layers and within\nlayers. Values will be broadcasted to all layers, if only two\nprobabilities are given, or to all layers and in-between and\nwithin layers, if only one probability is given. Dropout is\nomitted if  Dropout is\nomitted if 0.</li>\n<li><strong>residual:</strong>  Whether a layer is a residual layer. If <code>residual</code> is a\nsingle value, then layers will only be residual layers if their\nnumber of input and output features matches. Coordinates are not\nupdated through residual connections, independent of this\ntoggle.</li>\n<li><strong>activation:</strong>  Activation function that is used for the\n<code>UnrecordedEGNN</code> layers.</li>\n<li><strong>init:</strong>  Initializer that is used for network layers. First argument is\nthe module that should be initialized, the second is the\nnon-linearity, in case of a linear module.  The default\nnon-linearity should adhere to whatever is used for\n<code>activation</code>. See <code>bpp.model.egnn.parameter_init()</code>.</li>\n<li><strong>norm_cls:</strong>  Class instance of normalization module.</li>\n<li><strong>dropout_cls:</strong>  Class instance of dropout module.</li>\n<li><strong>disable:</strong>  Whether to disable layer-wise recomputation and store\nintermediate values for the back-propagation method. Used \nprimarily for debugging.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dims_node</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_edge</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">dims_gate</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">dims_pos</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]],</span> <span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"p\">()</span>,</span><span class=\"param\">\t<span class=\"n\">channels</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>,</span><span class=\"param\">\t<span class=\"n\">layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">dim_pos</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">num_encode</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">pos_scale</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">norm</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">clamp</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>,</span><span class=\"param\">\t<span class=\"n\">residual</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]],</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">init</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]]],</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\tnorm_cls: Union[Sequence[type[torch.nn.modules.module.Module]], type[torch.nn.modules.module.Module]] = &lt;class &#x27;torch.nn.modules.batchnorm.BatchNorm1d&#x27;&gt;,</span><span class=\"param\">\tdropout_cls: Union[Sequence[type[torch.nn.modules.module.Module]], type[torch.nn.modules.module.Module]] = &lt;class &#x27;torch.nn.modules.dropout.Dropout&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">disable</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Sequence</span><span class=\"p\">[</span><span class=\"nb\">bool</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "bpp.model.egnn.unrecorded.DeepUnrecordedEGNN.residual", "modulename": "bpp.model.egnn.unrecorded", "qualname": "DeepUnrecordedEGNN.residual", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.unrecorded.DeepUnrecordedEGNN.init", "modulename": "bpp.model.egnn.unrecorded", "qualname": "DeepUnrecordedEGNN.init", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.unrecorded.DeepUnrecordedEGNN.layers", "modulename": "bpp.model.egnn.unrecorded", "qualname": "DeepUnrecordedEGNN.layers", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "bpp.model.egnn.unrecorded.DeepUnrecordedEGNN.reset_parameters", "modulename": "bpp.model.egnn.unrecorded", "qualname": "DeepUnrecordedEGNN.reset_parameters", "kind": "function", "doc": "<p>Reset parameters.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "bpp.model.egnn.unrecorded.DeepUnrecordedEGNN.forward", "modulename": "bpp.model.egnn.unrecorded", "qualname": "DeepUnrecordedEGNN.forward", "kind": "function", "doc": "<p>Compute forward pass.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x:</strong>  Node features.</li>\n<li><strong>pos:</strong>  Node coordinates.</li>\n<li><strong>edge_index:</strong>  Graph connectivity.</li>\n<li><strong>edge_attr:</strong>  Edge features.</li>\n<li><strong>batch:</strong>  Node to batch mapping.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Tuple of updated node features and updated coordinates.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">pos</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">edge_index</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">edge_attr</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch_geometric</span><span class=\"o\">.</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">SparseTensor</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();